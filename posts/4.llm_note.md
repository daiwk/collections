# 概述

llm训练时的teacher forcing机制：生成第i个token的输入：
+ 推理时：是模型生成的第0到第i-1的序列
+ 训练时：训练数据中实际的token序列

例如输入的是12345，输入1的时候生成了8，那要预测3的时候，输入的就是18；而训练时输入的还是12

# SFT

## lora

+ lora的核心思想：微调前后模型的参数差异具有低秩性，所以可以用A和B两个矩阵来表示，这两个矩阵的秩是$$lora_{rank}$$
+ A一般是随机初始化，B用0初始化或者用很小的随机数初始化，为了保证在训练初期，lora不会对原始输出造成太大扰动
+ 参数$$lora_{alpha}$$用于缩放Lora输出，即$$W_{merge}=W+A*B*lora_{alpha}/lora_{rank}$$
+ 学习率一般开始的时候比较小，后面可以再调整，不过如果lora_alpha较大，可以适当减小学习率
+ 在推理的时候，可以先进行融合，其实就是算好$$W_{merge}$$，推理的时候直接用
