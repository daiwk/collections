## 计算机视觉

### cv数据集

[ResNet图像识别准确率暴降40个点！这个ObjectNet让世界最强视觉模型秒变水货](https://mp.weixin.qq.com/s/4kqswia0QKaj5J1505lLOg)

[实测超轻量中文OCR开源项目，总模型仅17M](https://mp.weixin.qq.com/s/enVx8sLoxmaSM8NlUL5IMQ)

[https://github.com/ouyanghuiyu/chineseocr_lite](https://github.com/ouyanghuiyu/chineseocr_lite)

### cv基础

[计算机视觉入门大全：基础概念、运行原理、应用案例详解](https://mp.weixin.qq.com/s/uCzd5HPjSUBXGhgvhw_2Cw)

[Pytorch 中的数据增强方式最全解释](https://mp.weixin.qq.com/s/HLdzPymLT3w6gR7lI1wR9A)

[传统计算机视觉技术落伍了吗？不，它们是深度学习的「新动能」](https://mp.weixin.qq.com/s/dIIWAKv9woLO8M0CyN8lsw)

[Deep Learning vs. Traditional Computer Vision](https://arxiv.org/pdf/1910.13796.pdf)

### cv历史

[历史需要重写？AlexNet之前，早有算法完成计算机视觉四大挑战](https://mp.weixin.qq.com/s/xo7bRNKEeT0QHcND6DxThg)

[图像分类最新技术综述论文: 21种半监督、自监督和无监督学习方法一较高低](https://mp.weixin.qq.com/s/tJaNpW7TyUowdn9JRBVnJQ)

### cnn相关

[67页综述深度卷积神经网络架构：从基本组件到结构创新](https://mp.weixin.qq.com/s/acvpHt4zVQPI0H5nHcg3Bw)

[A Survey of the Recent Architectures of Deep Convolutional Neural Networks](https://arxiv.org/pdf/1901.06032.pdf)

[卷积神经网络性能优化](https://zhuanlan.zhihu.com/p/80361782)

[解析卷积的高速计算中的细节，一步步代码带你飞](https://mp.weixin.qq.com/s/Ji2PjZowifkIdGlHJPwEaw)

### 图像分割

#### 图像分割综述

[最全综述 \| 图像分割算法](https://mp.weixin.qq.com/s/l6b1C0hH9mFbNevfsjE-5w)

[100个深度图像分割算法，纽约大学UCLA等最新综述论文](https://mp.weixin.qq.com/s/VXjNbMN0j0slZaJd8s8sKA)

#### MoCo

[何恺明一作，刷新7项检测分割任务，无监督预训练完胜有监督](https://mp.weixin.qq.com/s/-cXOUw9zJteVUkbpRMIWtQ)

[Momentum Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/abs/1911.05722)

#### PointRend

[何恺明团队又出神作：将图像分割视作渲染问题，性能显著提升！](https://mp.weixin.qq.com/s/2w_oy3SQB7-k5zq3CM6iSQ)

[Ross、何恺明等人提出PointRend：渲染思路做图像分割，显著提升Mask R-CNN性能](https://mp.weixin.qq.com/s/3vNnqCFTuVHQ58dZRinX4g)

[PointRend: Image Segmentation as Rendering](https://arxiv.org/abs/1912.08193)


#### Graph-FCN

[另辟蹊径，中科院自动化所等首次用图卷积网络解决语义分割难题](https://mp.weixin.qq.com/s/i_v1GoR-VzVxmy2Wm97t4w)

[Graph-FCN for image semantic segmentation](https://arxiv.org/pdf/2001.00335.pdf)

使用深度学习执行语义分割在图像像素分类方面取得了巨大进步。但是，深度学习提取高级特征时往往忽略了局部位置信息（local location information），而这对于图像语义分割而言非常重要。

为了避免上述问题，来自中科院自动化所、北京中医药大学的研究者们提出一个执行图像语义分割任务的图模型 Graph-FCN，该模型由全卷积网络（FCN）进行初始化。首先，通过卷积网络将图像网格数据扩展至图结构数据，这样就把语义分割问题转换成了图节点分类问题；然后，使用图卷积网络解决图节点分类问题。研究者称，这是首次将图卷积网络用于图像语义分割的尝试。该方法在 VOC 数据集上获得了有竞争力的 mIOU 性能，相比原始 FCN 模型有 1.34% 的性能提升。

### 目标检测

#### 自然场景文字定位

[ICDAR 2019论文：自然场景文字定位技术详解](https://mp.weixin.qq.com/s/l1rmGxOVrXKAaf4yYUt4kQ)

#### EfficientDet

[比当前SOTA小4倍、计算量少9倍，谷歌最新目标检测器EfficientDet](https://mp.weixin.qq.com/s/AA6F43A59Ybv7NcZ4jvSLg)

[EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070)

计算机视觉领域，模型效率已经变得越来越重要。在本文中，研究者系统地研究了用于目标检测的各种神经网络架构设计选择，并提出了一些关键的优化措施来提升效率。首先，他们提出了一种加权双向特征金字塔网络（weighted bi-directional feature pyramid network，BiFPN），该网络可以轻松快速地进行多尺度特征融合；其次，他们提出了一种复合缩放方法，该方法可以同时对所有骨干、特征网络和框/类预测网络的分辨率、深度和宽度进行统一缩放。基于这些优化，研究者开发了一类新的目标检测器，他们称之为EfficientDet。在广泛的资源限制条件下，该检测器始终比现有技术获得更高数量级的效率。具体而言，在没有附属条件的情况下，EfficientDet-D7在52M参数和326B FLOPS1的COCO数据集上实现了51.0 mAP的SOTA水平，体积缩小了4倍，使用的FLOPS减少了9.3倍，但仍比先前最佳的检测器还要准确（+0.3% mAP）。

推荐：本文探讨了计算机视觉领域的模型效率问题，分别提出了加权双向特征金字塔网络和复合缩放方法，进而开发了一种新的EfficientDet目标检测器，实现了新的 SOTA 水平。

#### YoloVxxx


[超全！YOLO目标检测从V1到V3结构详解](https://mp.weixin.qq.com/s/5weWze-75FwEjfbHDbpPCw)

[【目标检测】YOLOv4特征提取网络——CSPDarkNet结构解析及PyTorch实现](https://blog.csdn.net/EasonCcc/article/details/108879514)

### 图像识别

[显著提升图像识别网络效率，Facebook提出IdleBlock混合组成方法](https://mp.weixin.qq.com/s/tc7DaM8dkq7SjiXtPp4uHA)

[Hybrid Composition with IdleBlock: More Efficient Networks for Image Recognition](https://arxiv.org/pdf/1911.08609.pdf)

近年来，卷积神经网络（CNN）已经主宰了计算机视觉领域。自 AlexNet 诞生以来，计算机视觉社区已经找到了一些能够改进 CNN 的设计，让这种骨干网络变得更加强大和高效，其中比较出色的单个分支网络包括 Network in Network、VGGNet、ResNet、DenseNet、ResNext、MobileNet v1/v2/v3 和 ShuffleNet v1/v2。近年来同样吸引了研究社区关注的还有多分辨率骨干网络。作者认为目前实现高效卷积网络的工作流程可以分成两步：1）设计一种网络架构；2）对该网络中的连接进行剪枝。在第一步，作者研究了人类专家设计的架构与搜索得到的架构之间的共同模式：对于每种骨干网络，其架构都是由其普通模块和归约模块（reduction block）的设计所确定的。第二步会将某些连接剪枝去掉，这样就不能保证每个模块都有完整的信息交换了。Facebook AI 的研究者在这篇论文中通过在网络设计步骤中考虑剪枝，为图像识别任务设计了一种更高效的网络。他们创造了一种新的模块设计方法：Idle。

### 图像补全

[拍照总被路人甲抢镜？那就用这个项目消Ta](https://mp.weixin.qq.com/s/kgQBQz2u8aMzZaHFhWF_VQ)

### 文字检测与识别

[AAAI 2020 \| 旷视研究院：深度解读文字检测与识别新突破](https://mp.weixin.qq.com/s/1EewWtY70UgdMXm9mEifsQ)

### 图像合成

[SEAN: Image Synthesis with Semantic Region-Adaptive Normalization](https://arxiv.org/abs/1911.12861)

本论文要解决的问题是使用条件生成对抗网络（cGAN）生成合成图像。具体来说，本文要完成的具体任务是使用一个分割掩码控制所生成的图像的布局，该分割掩码的每个语义区域都具有标签，而网络可以根据这些标签为每个区域「添加」具有真实感的风格。尽管之前已经有一些针对该任务的框架了，但当前最佳的架构是 SPADE（也称为 GauGAN）。因此，本论文的研究也是以 SPADE 为起点的。具体来说，本文针对原始 SPADE 的两个缺陷提出了新的改进方案。本文在几个高难度的数据集（CelebAMaskHQ、CityScapes、ADE20K 和作者新建的 Facades 数据集）上对新提出的方法进行了广泛的实验评估。定量实验方面，作者基于 FID、PSNR、RMSE 和分割性能等多种指标对新方法进行了评估；定性实验方面，作者展示了可通过视觉观察进行评估的样本。

推荐：图像合成是近来非常热门的研究领域，世界各地的研究者为这一任务提出了许多不同的框架和算法，只为能合成出更具真实感的图像。阿卜杜拉国王科技大学和卡迪夫大学近日提出了一种新改进方案 SEAN，能够分区域对合成图像的内容进行控制和编辑（比如只更换眼睛或嘴），同时还能得到更灵活更具真实感的合成结果。有了这个技术，修图换眼睛时不用再担心风格不搭了。

[CVPR 2020 \| 让合成图像更真实，上交大提出基于域验证的图像和谐化](https://mp.weixin.qq.com/s/oV9vYbUmXOsdJsMuSGTjXg)

### 人脸识别

[面部识别必看！5篇顶级论文了解如何实现人脸反欺诈、跨姿势识别等](https://mp.weixin.qq.com/s/b2umP_9y6v6xuCdLbZvosg)

### CV相关比赛

[ICCV 2019 COCO & Mapillary挑战赛冠军团队技术分享](https://mp.weixin.qq.com/s/bJOUg9k_EHOrLu7Db7ANLA)

### 3D模型相关

[图像转换3D模型只需5行代码，英伟达推出3D深度学习工具Kaolin](https://mp.weixin.qq.com/s/srHmkY_t3ChFAzhvXG6RPA)

[内存计算显著降低，平均7倍实测加速，MIT提出高效、硬件友好的三维深度学习方法](https://mp.weixin.qq.com/s/kz5ja8K4rPD_m1GvUznByg)

[Point-Voxel CNN for Efficient 3D Deep Learning](https://arxiv.org/pdf/1907.03739.pdf)

[FaceBook开源PyTorch3D：基于PyTorch的新3D计算机视觉库](https://mp.weixin.qq.com/s/2EHv669PUqqgvAGz3XoZ6Q)

[https://github.com/facebookresearch/pytorch3d](https://github.com/facebookresearch/pytorch3d)


[PolyGen: An Autoregressive Generative Model of 3D Meshes](https://arxiv.org/pdf/2002.10880.pdf)

摘要：在本文中，来自 DeepMind 的研究者提出了一种直接建模网格的方法 PolyGen，该方法利用 Transformer 架构来循序地预测网格的顶点和表面。文中提出的 3D 网格深度生成模型 PolyGen 以对象类、三维像素和图像等一系列输入为条件，同时由于该模型是概率性的，因此它可以生成捕获模糊场景中不确定性的样本。

实验表明，该模型能够生成高质量、可用的网格，并为网格建模任务创建对数似然基准。研究者表示，PolyGen 模型能够生成连贯的、多样化的 3D 网格，并且相信可以扩展该模型在计算机视觉、机器人学和 3D 内容创建中的应用。

推荐：本文的亮点在于，研究者将网格生成问题作为自回归序列建模来处理，同时结合了 Transformers 和指针网络的优势，从而能够灵活地建模长度可变的网格序列。

### GNN+CV

[一文读懂：图卷积在基于骨架的动作识别中的应用](https://mp.weixin.qq.com/s/aMFFQBfVXgQr71nyjpyf0g)

[NTU RGB+D 120: A Large-Scale Benchmark for 3D Human Activity Understanding](https://arxiv.org/abs/1905.04757)

### CV最新进展

#### 半弱监督

[10亿照片训练，Facebook半弱监督训练方法刷新ResNet-50 ImageNet基准测试](https://mp.weixin.qq.com/s/t1Js479ZRDAw1XzPdx_nQA)

[https://github.com/facebookresearch/semi-supervised-ImageNet1K-models](https://github.com/facebookresearch/semi-supervised-ImageNet1K-models)

[https://ai.facebook.com/blog/billion-scale-semi-supervised-learning](https://ai.facebook.com/blog/billion-scale-semi-supervised-learning)

Facebook将该方法称为“半弱监督”(semi-weak supervision)，是结合了半监督学习和弱监督学习者两种不同训练方法的有点的一种新方法。通过使用teacher-student模型训练范式和十亿规模的弱监督数据集，它为创建更准确、更有效的分类模型打开了一扇门。如果弱监督数据集(例如与公开可用的照片相关联的hashtags)不能用于目标分类任务，该方法还可以利用未标记的数据集来生成高度准确的半监督模型。

#### advprop

[Quoc Le推新论文：打破常规，巧用对抗性样本改进图像识别性能](https://mp.weixin.qq.com/s/lBEihC-4GgxlfWHvZUx42g)

[Adversarial Examples Improve Image Recognition](https://arxiv.org/pdf/1911.09665.pdf)

[https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet)

对抗样本经常被认为是卷积神经网络的一个威胁。而研究者在这篇论文中提出了相反的论点：对抗网络可以被用来提升图像识别模型的准确率，只要使用正确的方式。研究者在这里提出了 AdvProp，这是一个增强对抗训练方法，能够将对抗样本视为额外样本，以方式过拟合。这一方法的关键在于对对抗样本使用了分离的辅助批归一化，因为它们和正常样本的隐藏分布不同。

研究说明，AdvProp 在很多图像识别任务上提升了一系列模型的性能，而且当模型变得更大的时候，性能也会更好。例如，通过将 AdvProp 用在最新的 EfficientNet-B7 模型上，使用 ImageNet 进行训练，研究者可以取得性能点的提升，如 ImageNet (+0.7%)、ImageNet-C (+6.5%)、ImageNet-A (+7.0%)、Stylized- ImageNet (+4.8%）。而在 增强的 EfficientNet-B8 上，这一方法在没有额外数据的情况下达到了 SOTA——85.5% 的 ImageNet top-1 精确度。这一结果超越了使用 3.5B Instagram 数据和 9.4 倍参数量的最佳模型。

#### 稀疏性+cv

[Fast Sparse ConvNets](https://arxiv.org/abs/1911.09723v1)

从历史发展的角度来看，对有效推理（efficient inference）的追求已经成为研究新的深度学习架构和构建块背后的驱动力之一。近来的一些示例包括：压缩和激发模块（squeeze-and-excitation module）、Xception 中的深度级可分离卷积（depthwise seperable convolution）和 MobileNet v2 中的倒置瓶颈（inverted bottleneck）。在所有这些示例中，生成的构建块不仅实现了更高的有效性和准确率，而且在领域内得到广泛采用。在本文中，来自 DeepMind 和 Google 的研究者们进一步扩展了神经网络架构的有效构建块，并且在没有结合标准基本体（standard primitive）的情况下，他们主张用稀疏对应（sparse counterpart）来替换这些密集基本体（dense primitive）。利用稀疏性来减少参数数量的想法并不新鲜，传统观点也认为理论浮点运算次数的减少不能转化为现实世界的效率增益。

研究者通过提出一类用于 ARM 和 WebAssembly 的有效稀疏核来纠正这种错误观点，并且进行开源作为 XNNPACK 库的组成部分。借助于稀疏标准体（sparse primitive）的有效实现，研究者表明，MobileNet v1、MobileNet v2 和 EfficientNet 架构的稀疏版本在有效性和准确率曲线（efficiency-accuracy curve）上显著优于强大的密集基线（dense baseline）。在骁龙 835 芯片上，他们提出的稀疏网络比同等的密集网络性能增强 1.3-2.4 倍，这几乎相当于 MobileNet-family 一整代的性能提升。研究者希望他们的研究成果可以促进稀疏性更广泛地用作创建有效和准确深度学习架构的工具。

#### 自监督+半监督EnAET

[华为美研所推出EnAET：首次用自监督学习方法加强半监督学习](https://mp.weixin.qq.com/s/rvxjBdBUkwsO-AN39k3FrQ)

[EnAET: Self-Trained Ensemble AutoEncoding Transformations for Semi-Supervised Learning](https://arxiv.org/abs/1911.09265)

[https://github.com/wang3702/EnAET](https://github.com/wang3702/EnAET)

#### 无监督SimCLR

[Hinton组力作：ImageNet无监督学习最佳性能一次提升7%，媲美监督学习](https://mp.weixin.qq.com/s/8RU3qLWkbP86-6dU2w023A)

[A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/pdf/2002.05709.pdf)

在这篇论文中，研究者发现：

+ 多个数据增强方法组合对于对比预测任务产生有效表示非常重要。此外，与有监督学习相比，数据增强对于无监督学习更加有用；
+ 在表示和对比损失之间引入一个可学习的非线性变换可以大幅提高模型学到的表示的质量；
+ 与监督学习相比，对比学习得益于更大的批量和更多的训练步骤。

基于这些发现，他们在 ImageNet ILSVRC-2012 数据集上实现了一种新的半监督、自监督学习 SOTA 方法——SimCLR。在线性评估方面，SimCLR 实现了 76.5% 的 top-1 准确率，比之前的 SOTA 提升了 7%。在仅使用 1% 的 ImageNet 标签进行微调时，SimCLR 实现了 85.8% 的 top-5 准确率，比之前的 SOTA 方法提升了 10%。在 12 个其他自然图像分类数据集上进行微调时，SimCLR 在 10 个数据集上表现出了与强监督学习基线相当或更好的性能。

#### 图像对抗攻击

[胶囊网络显神威：Google AI和Hinton团队检测到针对图像分类器的对抗攻击](https://mp.weixin.qq.com/s/ux81Z5H2ZcC0Rq8Hi6c27w)

