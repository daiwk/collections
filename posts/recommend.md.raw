下载本文pdf：[https://github.com/daiwk/collections/blob/master/pdfs/recommend.pdf](https://github.com/daiwk/collections/blob/master/pdfs/recommend.pdf)

# 推荐系统整体梳理

[https://daiwk.github.io/posts/links-navigation-recommender-system.html](https://daiwk.github.io/posts/links-navigation-recommender-system.html)

[https://github.com/Doragd/Algorithm-Practice-in-Industry](https://github.com/Doragd/Algorithm-Practice-in-Industry)

王喆的机器学习笔记系列：

[https://github.com/wzhe06/Reco-papers](https://github.com/wzhe06/Reco-papers)

[https://github.com/wzhe06/Ad-papers](https://github.com/wzhe06/Ad-papers)

深度学习传送门系列：

[https://github.com/imsheridan/DeepRec](https://github.com/imsheridan/DeepRec)

推荐系统遇上深度学习系列：

链接: [https://pan.baidu.com/s/1jZkJ2d9WckbZL48aGFudOA](https://pan.baidu.com/s/1jZkJ2d9WckbZL48aGFudOA)  密码:kme3

[推荐系统技术演进趋势：召回->排序->重排](https://mp.weixin.qq.com/s/pCbwOEdEfAPSLGToAFXWOQ)

[推荐系统的发展与2019最新论文回顾](https://mp.weixin.qq.com/s/C6e8Pn9IoKCMuQshh_u6Xw)

[深度推荐系统2019年度阅读收藏清单](https://mp.weixin.qq.com/s/u6r5FiPbfVF31Q38OIn6xA)

[推荐工业界实战角度详解TensorFlow中Wide & Deep源码（三）](https://mp.weixin.qq.com/s/ur7xwdY86KlWU3qpmqUcog)

# 常用机器学习基础

## mse vs cross-entropy

不一定回归就用mse，分类才用交叉熵

[https://zhuanlan.zhihu.com/p/362496849](https://zhuanlan.zhihu.com/p/362496849)

[https://www.zhihu.com/question/415245797/answer/1791746717](https://www.zhihu.com/question/415245797/answer/1791746717)

[https://zhuanlan.zhihu.com/p/304462034](https://zhuanlan.zhihu.com/p/304462034)

[https://blog.csdn.net/u011508640/article/details/72815981](https://blog.csdn.net/u011508640/article/details/72815981)

各种分布：

[https://github.com/graykode/distribution-is-all-you-need](https://github.com/graykode/distribution-is-all-you-need)

## cross-entroy vs nllloss

[聊一聊机器学习的MLE和MAP：最大似然估计和最大后验估计](https://mp.weixin.qq.com/s?__biz=MzI4MDYzNzg4Mw==&mid=2247552799&idx=3&sn=87cdfb929865571ec96738c42deb3240&chksm=ebb737cbdcc0bedd74395a68fb76796f1c102a6129ee2e81e0932da786ec58450d415a448a6e&scene=27)

贝叶斯公式：

XXX
P(\theta \mid X)=\frac{P(X \mid \theta) \times P(\theta)}{P(X)}
XXX

+ 先验（prior）：$$P(\theta)$$，没有观测到任数据时对$$\theta$$的预先判断，例如假设硬币很大概率是均匀的，很小概率不均匀；**随着数据量的增加，先验的影响力越来越小。**
+ 后验（posterior）：$$P(\theta \mid X)$$，最终的参数分布
+ 似然（likelihood）：$$P(X \mid \theta)$$，假设$$\theta$$已知后，我们观察到的数据应该是什么样的

结论：

+ 最大似然估计（MLE, max likelihood estimation）：等价于NLL(negative log likelihood)，即交叉熵
+ 最大后验估计（MAP, max a posteriori）：假设参数服从高斯分布，等价于**MLE+L2正则**

[https://blog.csdn.net/geter_CS/article/details/84857220](https://blog.csdn.net/geter_CS/article/details/84857220)

[https://blog.csdn.net/qq_22210253/article/details/85229988](https://blog.csdn.net/qq_22210253/article/details/85229988)

CrossEntropyLoss就是把Softmax–Log–NLLLoss合并成一步

![cnllloss](../assets/ce-nllloss.png)

## softplus

[https://stackoverflow.com/questions/44230635/avoid-overflow-with-softplus-function-in-python](https://stackoverflow.com/questions/44230635/avoid-overflow-with-softplus-function-in-python)

```python
import numpy as np
import math

def softplus_np(x): return np.log1p(np.exp(-np.abs(x))) + np.maximum(x, 0)
def softplus_math(x): return math.log1p(math.exp(-abs(x))) + max(x, 0)
```

因为

```python
log(1+exp(x)) = log(1+exp(x)) - log(exp(x)) + x = log(1+exp(-x)) + x
```

同理，如果要求```log(1+exp(-x))```的稳定版本，可以

```python
def softplus_math(x): return math.log1p(math.exp(-abs(x))) + max(x, 0)
```

## 一些tricks

[深度学习刷SOTA有哪些trick？](https://www.zhihu.com/question/540433389/answer/2549775065)

# 特征、样本、数据流

[浅谈微视推荐系统中的特征工程](https://mp.weixin.qq.com/s/NqVP0ksfLiRLSGkuWxiz5A)

[推荐系统之数据与特征工程](https://mp.weixin.qq.com/s/FbIO1C4Xt2WIdIln9SY8Ug)

[稠密特征加入CTR预估模型的方法汇总](https://mp.weixin.qq.com/s/xhxBbSYva4g9wUvQ5RIdVA)

# tf开源库

[社区分享 | TensorFlow Recommenders-Addons 现已开源，让推荐系统效果更好！](https://mp.weixin.qq.com/s/LKIuLYz8fP3BL3cB1CsHlw)

[https://github.com/tensorflow/recommenders-addons](https://github.com/tensorflow/recommenders-addons)

# 预估架构

## HugeCTR

点击率预估的训练传统上存在着几个困扰着广大开发者的问题：巨大的哈希表（Embedding Table），较少的矩阵计算，大量的数据吞吐。

HugeCTR 是首个全部解决以上问题的开源 GPU 训练框架，与现有 CPU 和混合 CPU / GPU 解决方案相比，它的速度提高了 12 倍至 44 倍。HugeCTR 是一种端到端训练解决方案，其所有计算都在 GPU 上执行，而 CPU 仅用于 I / O。GPU 哈希表支持动态缩放。它利用 MPI 进行多节点训练，以支持任意大的嵌入尺寸。它还还支持混合精度训练，在 Volta GPU 及其后续版本上可以利用 Tensor cores 进一步加速。

[如何解决点击率预估？英伟达专家详解HugeCTR训练框架（二）](https://mp.weixin.qq.com/s/14ETFLjojsP7Aop4_THVKQ)

[Merlin HugeCTR 分级参数服务器简介](https://mp.weixin.qq.com/s/bfnQ3glPYA0sAgZlntTDUw)

## BOX
大规模深度学习广告系统的分布式分层GPU参数服务器

[Distributed Hierarchical GPU Parameter Server for Massive Scale Deep Learning Ads Systems](https://arxiv.org/pdf/2003.05622.pdf)

# 索引架构

## ANN索引

annoy hnsw faiss pq

## 暴力召回ANN加速

[https://kexue.fm/archives/9336](https://kexue.fm/archives/9336)

大致思想，CUR分解：query和item的MxN打分矩阵，分解成F(Mxk1), G(k1xk2), H(k2xN)三个矩阵

+ Mxk1矩阵：原矩阵里搞k1列出来，即选出k1个种子item，得到F
+ k2xN矩阵：原矩阵里搞k2列出来，即选出k2个种子query，得到H
+ k1xk2矩阵：即矩阵1和矩阵2求交集，比如矩阵1是抽的第1,23,54列出来，矩阵2是抽的第4,80行出来，那交集元素就是(1,4),(1,80),(23,4),(23,80),(54,4),(54,80)这6个点，构成k1xk2矩阵，然后算一下伪逆得到G

建索引：
+ 挑出种子query，和所有item两两计算相似度，得到H矩阵
+ 挑出种子item，和种子query两两计算相似度，再算伪逆，得到G矩阵
+ 计算G*H，存起来

检索：
+ 输入的query和k1个种子item算一下相似度，得到1xk1的矩阵q
+ q和G*H相乘，就能得到q和每个item的相似度了
  + 【这步可以ann化】：GH就是k1*N，按列来看，就是N个k1维向量，相当于N个item向量，扔到annlib里去就行了，而输入的q也是一个k1维向量，就可以ann了


## BLISS

[BLISS: A Billion scale Index using Iterative Re-partitioning](https://gaurav16gupta.github.io/papers/BLISS_KDD2022.pdf)


# 召回

[360展示广告召回系统的演进](https://mp.weixin.qq.com/s/QqWGdVGVxSComuJT1SDo0Q)

[推荐场景中深度召回模型的演化过程](https://mp.weixin.qq.com/s/AHuXCH1Z6gKoIkR5MGgLkg)

[https://github.com/imsheridan/DeepRec/tree/master/Match](https://github.com/imsheridan/DeepRec/tree/master/Match)

[精准推荐的秘术：阿里解耦域适应无偏召回模型详解](https://mp.weixin.qq.com/s/0Cbc3aAYTeFqLDutLBXJmA?notreplace=true)对应[Co-training Disentangled Domain Adaptation Network for Leveraging Popularity Bias in Recommenders](https://ir.webis.de/anthology/2022.sigirconf_conference-2022.10/)


[谈谈文本匹配和多轮检索](https://mp.weixin.qq.com/s/uoEX0TjJZmyquNch5Wikvg)

[搜索中的深度匹配模型](https://mp.weixin.qq.com/s/lcyw_kHNxPB-DUfNzTaj5g)

## 协同

### Swing

[Large Scale Product Graph Construction for Recommendation in E-commerce](https://arxiv.org/pdf/2010.05525.pdf)

score(i,j) = 0

+ 找到同时点过i和j的用户集合A，对集合A里的用户两两组合
  + s=1/(这两个用户的共同点击数+1)（如果两个用户的交集很大，说明这个item并不独特，要惩罚，类似idf）
  + score(i,j) += s （累加每个pair对的得分得到最终得分）

![swing](../assets/swing.png)

## 内积、余弦和L2

![](../assets/L2-innerproduct-hnsw.png)

给定a，找到和它最像的b

XXX
ab=||a||cos\theta ||b||
XXX

如果用内积，会找$$cos\theta ||b||$$最大的b出来，可能是夹角小，也可能是模大的b，所以可能偏热门

## DSSM

参考[Modeling Interestingness with Deep Neural Networks](https://www.microsoft.com/en-us/research/wp-content/uploads/2014/10/604_Paper.pdf)

对应的[ppt](https://github.com/daiwk/collections/blob/master/assets/dssm_ppt.pdf)

### 2013年CIKM的dssm

[Learning Deep Structured Semantic Models for Web Search using Clickthrough Data](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/cikm2013_DSSM_fullversion.pdf)

相当于一个q，和每个d分别算cos。

XXX
R(Q,D)=cosine(y_Q,y_D)=\frac{y_Q^Ty_D}{\left \| y_Q \right \|\left \| y_D \right \|}
XXX

所以given Q点击D的概率就是：

XXX
P(D|Q)=\frac{exp(\gamma R(Q,D))}{\sum _{D'\in \textbf{D}}exp(\gamma R(Q,D'))}
XXX

其中的$$\gamma$$是平滑因子。这里的$$\textbf{D}$$是需要rank的Documents的集合，理想情况肯定是全集了。实际上定义$$(Q,D^+)$$为一个query和点击文档的pair对，通过一个$$D^+$$和N个随机选的未点击的文档$$D_j^-,j=1,...,N$$近似。

所以训练时，在训练集上，给定query，有点击doc的概率最大化就是我们的目标(其中的$$\Lambda$$是网络参数)：

XXX
L(\Lambda)=-\log \prod _{(Q,D^+)}P(D^+|Q)
XXX

Word Hashing：例如，一个英文单词是”good”，那么会先在头尾各补上一个”#”，处理成”#good#”，然后拆成n-gram（假设n=3，也就是tri-gram，那就是”#go”，“goo”，”ood”，”od#”这么多个”新”词）。这样，可以把原来500k的词典缩到300k，可以有效缓解词典太大的问题，而且因为英文就26个字母，这样做也解决了新单词的OOV问题。

![dssm_2013cikm](../assets/dssm_2013cikm.png)

[https://blog.csdn.net/zjrn1027/article/details/80170966](https://blog.csdn.net/zjrn1027/article/details/80170966)

相似度衡量可以使用cos，而最终的loss可以用hinge loss：

设置一个margin $$m$$，query $$V_Q$$，正样本$$V_{A^+}$$，负样本$$V_{A^-}$$，如果**正负样本的相似度之差**小于边界值，那就还需要优化，如果**已经大于等于边界值**了，说明**模型已经能区分**了，所以用hinge loss：

XXX
L=max(0, m - (cos(V_Q,V_{A^+} - cos(V_Q, V_{A^-}))))
XXX

tf算cos

```python
    def getCosineSimilarity(q, a):
        q1 = tf.sqrt(tf.reduce_sum(tf.multiply(q, q), 1))
        a1 = tf.sqrt(tf.reduce_sum(tf.multiply(a, a), 1))
        mul = tf.reduce_sum(tf.multiply(q, a), 1)
        cosSim = tf.div(mul, tf.multiply(q1, a1))
        return cosSim
```

tf算hinge

```python
    def getLoss(trueCosSim, falseCosSim, margin):
        zero = tf.fill(tf.shape(trueCosSim), 0.0)
        tfMargin = tf.fill(tf.shape(trueCosSim), margin)
        with tf.name_scope("loss"):
            losses = tf.maximum(zero, tf.subtract(tfMargin, tf.subtract(trueCosSim, falseCosSim)))
            loss = tf.reduce_sum(losses)
        return loss
```

使用

```python
        self.trueCosSim = self.getCosineSimilarity(question2, trueAnswer2)
        self.falseCosSim = self.getCosineSimilarity(question2, falseAnswer2)
        self.loss = self.getLoss(self.trueCosSim, self.falseCosSim, self.margin)
```

### multiview dssm

[A Multi-View Deep Learning Approach for Cross Domain User Modeling in Recommendation Systems](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/frp1159-songA.pdf)

[https://blog.csdn.net/shine19930820/article/details/78810984](https://blog.csdn.net/shine19930820/article/details/78810984)

现在很多公司都不仅仅只有一个产品，而是有**多个产品线**。比如微软可能就有搜索、新闻、appstore、xbox等产品，如果将用户在这些产品上的行为（反馈）统一在一起训练一个深度学习网络，就能很好的解决**单个产品上**（用户）**冷启动、稀疏**等问题。

#### 概述

&nbsp;

![multiview-dnn](../assets/multiview-dnn.png)

一个产品线就是一个view，一条训练样本只有user+1个view，其他view置0。

总体的优化目标是保证在所有视图上user和正向反馈的item的相似度大于随机选取的无反馈或者负向反馈的相似度，并且越大越好。

XXX
p=\underset{W_u,W_1,...W_v}{argmax}\sum ^N_{j=1}\frac{exp(\alpha _a cos(Y_u,Y_{a,j})}{\sum _{X'\in R^{d_a}}exp(\alpha cos(Y_u,f_a(X',W_a)))}
XXX

其中的$$f_i(X_i,W_i)$$是$$X_i$$到$$Y_i$$的变换。有一个用户view，加上$$v$$个辅助(auxiliary)的item view。$$X_i\in R^{d_i}$$，即每个view有自己的特征空间。对于第$$j$$条样本，它只有第$$i$$个auxiliary view是有值的，其他view都是0。

tf代码：[https://github.com/InsaneLife/dssm/blob/master/multi_view_dssm_v3.py](https://github.com/InsaneLife/dssm/blob/master/multi_view_dssm_v3.py)

### 降维

#### top features

&nbsp;

对于user features，选取top-k最频繁的features。并通过TF-IDF过滤掉最常用的特征。

#### k means

&nbsp;

kmeans的公式如下：

XXX
\underset{C_1,...,C_k}{argmin}\sum ^N _{i=1} \min _{C_j\in \{C_1,...,C_k\}}distance(X_i,C_j)
XXX

通过K-means对相似的特征群分组为同一个cluster并生成新的特征，共生成k个新特征。生成的特征向量$$Y_i$$是一个$$K$$维的向量，第$$i$$维是第$$i$$个cluster中features的出现数。

具体地，使用一个长度为$$U$$的vector $$f_i$$，$$U$$是训练集中的用户数，$$f_i(j)$$表示用户$$i$$有feature $$j$$的次数。将每个$$f_i$$进行归一化。这样，对于每一个用户向量$$f_i$$，可以产生它的降维了的用户向量$$Y_i$$（假设feature $$a$$分配给了cluster $$Cls(a)$$，$$1\le Cls(a)\le K$$）：

XXX
Y_i(j)=\sum _{a:X_i(a)>0 \& Cls(a) = j}f_i(a)
XXX

想要抽出reasonable的feature数目，需要比较大的cluster数$$K$$。因为如果cluster数比较少，那一个cluster里就会有非常多的用户feature，很难学到有用的pattern。在本文中，设置$$K=10000$$，平均每个cluster里大概有350个feature。因为cluster数比较大，所以用mr版的kmeans。

#### Local sensitive Hashing

&nbsp;

通过一个随机的矩阵将数据映射到低维向量空间上，并且**保持原始空间上的pairwis cos距离**在**新的空间上**仍然获得**保留**。

原始矩阵$$d$$维，降到$$k$$维，所以对应的矩阵是$$A\in R^{d\times k}$$。所以$$A$$中有$$k$$个映射，每个映射$$A_i$$都将$$X$$映射到$$Y_i$$，输出的$$Y_i\in R^k$$。计算方式如下：

XXX
Y_i=\left\{\begin{matrix}
1,&if\ A_iX\ge 0\\ 
0,&else
\end{matrix}\right.
XXX

计算$$X_1$$，$$X_2$$的cos相似度是$$cos(\frac{H(Y_1,Y_2)}{k}\pi)$$，其中，$$X_1,X_2\in R^d$$。$$H(Y_1,Y_2)$$是LSH输出向量的汉明距离。为了保持cos相似度的高准确率，需要把$$k$$设得比较大，这里和k-means一样，$$k=10000$$。

因为对每个向量算LSH是相互独立的，所以这一步是可以高度并行化的。但是，在我们的case里，有10000的$$k$$，有3.5M的$$d$$，所以相当于要把包括了$$3.5M\times 10^4$$个服从$$N(0,1)$$浮点数的$$A$$存到每个节点的内存里，也就是300G的内存消耗，这是肯定不行的。有很多解决方法，大部分方法是生成一个sparse的矩阵$$A$$【kdd06的[Very sparse random projections](https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf)】。

而本文用了[Online Generation of Locality Sensitive Hash Signatures](https://pdfs.semanticscholar.org/db21/730d2e0e2aa1f148a5411ea23ae7ceea574a.pdf)里提到的pooling trick。

保存一个size是$$m$$的pool $$B$$，每个元素是从$$N(0,1)$$中随机出来的浮点数，m远小于transition matrix $$A$$的size。要获取$$A_{ij}$$的一条记录，就是使用关于$$i,j$$的一致性hash的方法在$$B$$中找到一个index，然后查出它的值。在本文中，设置$$m=1000000$$，将单节点的内存损耗从100G缩减到10M，可以直接用mr搞啦。

#### 减少训练样本数

&nbsp;

每个用户在每个域都有大量的日志数据，将每个用户在每个域只选取一个user-item对，具体为用户特征-用户在**此域**喜欢的所有item的**平均分数**。

## YoutubeDNN

[https://daiwk.github.io/posts/dl-youtube-video-recommendation.html](https://daiwk.github.io/posts/dl-youtube-video-recommendation.html)

参考[http://www.sohu.com/a/155797861_465975](http://www.sohu.com/a/155797861_465975)

参考[https://zhuanlan.zhihu.com/p/25343518](https://zhuanlan.zhihu.com/p/25343518)

[Deep neural networks for youtube recommendations](https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45530.pdf)

YouTube是世界上最大的视频上传、分享和发现网站，YouTube推荐系统为超过10亿用户从不断增长的视频库中推荐个性化的内容。整个系统由两个神经网络组成：**候选生成网络**和**排序网络**。候选生成网络从**百万量级**的视频库中生成**上百个**候选，排序网络对候选进行打分排序，输出**排名最高的数十个结果**。

### 候选生成网络（Candidate Generation Network）

候选生成网络将推荐问题建模为一个**类别数极大的多分类问题**：对于一个Youtube用户，使用其观看历史（视频ID）、搜索词记录（search tokens）、人口学信息（如地理位置、用户登录设备）、二值特征（如性别，是否登录）和连续特征（如用户年龄）等，对视频库中所有视频进行多分类，得到每一类别的分类结果（即每一个视频的推荐概率），最终输出概率较高的几百个视频。===>即，【使用**用户特征**，对所有视频进行分类，得到**和这个用户最相关的几百个候选结果。**】

将推荐看成分类问题，用户$$U$$在上下文$$C$$中，选择视频$$i$$的概率是：

XXX
P(w_t=i|U,C)=\frac{e^{v_iu}}{\sum _{j\in V}e^{v_ju}}
XXX

其中，$$v_i\in R^N$$是第i个视频的emb，$$u\in R^N$$是用户的emb，两个emb都是N维的，这里看起来是用内积$$v_iu$$把它们变成一个数。

由于视频有百万量级，所以做这么一个超大规模的分类，需要，并且使用的是到的样本**通过importance sampling进行负采样**(参考[On using very large target vocabulary for neural machine translation](http://www.aclweb.org/anthology/P15-1001))。对每一个example而言，他的cross-entropy是在true label和采样的负类中求min。在实践中，采样了数千个负类，比传统的softmax有将近100倍的速度提升。

另一种做法是hierarchical softmax(参考[Hierarchical probabilistic neural network language model](https://www.iro.umontreal.ca/~lisa/pointeurs/hierarchical-nnlm-aistats05.pdf))，但实践中效果没那么好。因为在hsoftmax中，遍历树里的每一个节点时，会引入对经常是毫无联系的类别的分辨，使得分类问题变得更困难以至于效果变差。

在线serving时，由于低延迟的要求，需要有对类别数是sublinear的时间复杂度的近邻检索方法，之前youtube的系统使用的是hashing的方法，即[Label partitioning for sublinear ranking](http://www.thespermwhale.com/jaseweston/papers/label_partitioner.pdf)。因为在线的时候，softmax的输出没啥用，所以打分问题就变成了一个在点积的空间上进行最近邻检索的问题，有很多通用库可以用，例如基于LSH的ann算法：[ An Investigation of Practical Approximate Nearest Neighbor Algorithms](http://papers.nips.cc/paper/2666-an-investigation-of-practical-approximate-nearest-neighbor-algorithms.pdf)。

注：

item-embedding也可以参考[https://zhuanlan.zhihu.com/p/24339183?refer=deeplearning-surfing](https://zhuanlan.zhihu.com/p/24339183?refer=deeplearning-surfing)里说的[Item2vec: Neural Item Embedding for Collaborative Filtering](https://arxiv.org/abs/1603.04259)的想法，把item视为word，用户的行为序列视为一个集合，item间的共现为正样本，并按照item的频率分布进行负样本采样，相似度的计算还只是利用到了item共现信息，缺点是：忽略了user行为序列信息; 没有建模用户对不同item的喜欢程度高低。

### Modeling Expected Watch Time

训练用的是logistic regression加上cross-entropy，

logit和sigmoid的关系，odds表示一个事件的几率，即该事件**发生与不发生的概率比值**，x表示logit：

XXX
\begin{aligned}
&y = \frac{1}{1+exp(-x)}\\
&exp(-x) = \frac{1}{y}-1=\frac{1-y}{y}\\
&-x=log(\frac{1-y}{y})\\
&logit=x=log(\frac{y}{1-y})=log(odds)
\end{aligned}
XXX

假设第i个正样本的播放时长是$$T_i$$，使用weighted logistic regression，将正样本的权重设为播放时长，而负样本的权重设为1，这样，假设总共有N个样本，有k个被点击了，就相当于有了$$\sum T_i$$个正样本，N-k个负样本。所以odds就是正样本数/负样本数=$$\frac{\sum T_i}{N-k}$$。

而实际中，点击率P很低，也就是k很小，而播放时长的期望是$$E(T)=\frac{\sum T_i}{N}$$，所以$$E(T)$$约等于$$E(T)(1+P)$$，约等于odds，即$$\frac{\sum T_i}{N-k}$$

最后在inference的serving中，直接使用$$e^{Wx+b}$$来产出odds，从而近似expected watch time。

参考[https://en.wikipedia.org/wiki/Logistic_regression](https://en.wikipedia.org/wiki/Logistic_regression)

odds是平均时长，训练时输入给sigmoid的是logit，

XXX
wx+b = logit = log odds
XXX

所以，infer的时候：

XXX
E(T) = odds = e ^{logit} = e ^{log odds} = e^{wx+b}
XXX

参考tf的weighted sigmoid：```weighted_cross_entropy_with_logits```: [https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits](https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits)

正常的sigmoid：

```python
labels * -log(sigmoid(logits)) +
    (1 - labels) * -log(1 - sigmoid(logits))
```

weighted sigmoid只对正样本加权：

```python
labels * -log(sigmoid(logits)) * pos_weight +
    (1 - labels) * -log(1 - sigmoid(logits))
```

![youtube-dnn-recsys-architecture](../assets/youtube-dnn-recsys-architecture.png)

### 代码实现

[https://github.com/ogerhsou/Youtube-Recommendation-Tensorflow/blob/master/youtube_recommendation.py](https://github.com/ogerhsou/Youtube-Recommendation-Tensorflow/blob/master/youtube_recommendation.py)

关于数据集：

[https://github.com/ogerhsou/Youtube-Recommendation-Tensorflow/commit/e92bac1b8b5deb0e93e996b490561baaea60bae8](https://github.com/ogerhsou/Youtube-Recommendation-Tensorflow/commit/e92bac1b8b5deb0e93e996b490561baaea60bae8)

使用的是[https://github.com/facebookresearch/fastText/blob/master/classification-example.sh](https://github.com/facebookresearch/fastText/blob/master/classification-example.sh)

在init_data函数中，给每个__label__xx编了个号，如：

```shell
__label__6 0
__label__12 1
__label__14 2
__label__7 3
```

然后read_data的时候，y就用这个编号来表示（假装是时长）：

```python
y.append(label_dict[line[0]])
```

而使用的是nce_loss(参考[https://daiwk.github.io/posts/knowledge-tf-usage.html#tfnnnceloss](https://daiwk.github.io/posts/knowledge-tf-usage.html#tfnnnceloss))：

```python
ce_weights = tf.Variable(
    tf.truncated_normal([n_classes, n_hidden_1],
                        stddev=1.0 / math.sqrt(n_hidden_1)))
nce_biases = tf.Variable(tf.zeros([n_classes]))

loss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_weights,
                     biases=nce_biases,
                     labels=y_batch,
                     inputs=pred,
                     num_sampled=10,
                     num_classes=n_classes))

cost = tf.reduce_sum(loss) / batch_size
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)
out_layer = tf.matmul(pred, tf.transpose(nce_weights)) + nce_biases
```


## 采样

batch内shuffle采样（有放回）

[On Sampling Strategies for Neural Network-based Collaborative Filtering](https://arxiv.org/pdf/1706.07881.pdf)

[浅谈个性化推荐系统中的非采样学习](https://mp.weixin.qq.com/s/OGLJx-1tGYYuLWFricfRKg)

[Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations](https://dl.acm.org/doi/10.1145/3298689.3346996)

### NCE/负采样/sampled-softmax等

[求通俗易懂解释下nce loss？](https://www.zhihu.com/question/50043438/answer/2529305073)

[http://demo.clab.cs.cmu.edu/cdyer/nce_notes.pdf](http://demo.clab.cs.cmu.edu/cdyer/nce_notes.pdf)

[自然语言处理-word2vec-负采样/Negative Sampling](https://zhuanlan.zhihu.com/p/144146838)

[https://www.tensorflow.org/extras/candidate_sampling.pdf](https://www.tensorflow.org/extras/candidate_sampling.pdf)

下载了一份：[https://github.com/daiwk/collections/blob/master/assets/candidate_sampling.pdf](https://github.com/daiwk/collections/blob/master/assets/candidate_sampling.pdf)

[推荐系统遇上深度学习(七十二)-[谷歌]采样修正的双塔模型](https://www.lizenghai.com/archives/38343.html)

## 召回常用Loss

[表示学习中的7大损失函数梳理](https://mp.weixin.qq.com/s/XN-ugqsziXDjj1Ax8EJD0A)

### Contrastive Loss

[A Comprehensive Survey on Self-Supervised Learning for Recommendation](https://arxiv.org/pdf/2404.03354)

[最新综述 | SSL4Rec: 全面探索自监督学习时代的推荐算法 (含开源代码和资料)](https://mp.weixin.qq.com/s/XvV67RK_9V56Sn5ncIBQSQ)

[https://github.com/HKUDS/SSLRec](https://github.com/HKUDS/SSLRec)

### Triplet Loss

### InfoNce Loss

[Self-supervised Learning for Large-scale Item Recommendations](https://arxiv.org/pdf/2007.12865.pdf)

v3有两个图：[https://arxiv.org/pdf/2007.12865v3.pdf](https://arxiv.org/pdf/2007.12865v3.pdf)

![ssl1](../assets/ssl-1.png)

![ssl1](../assets/ssl-2.png)


### Focal Loss


### Circle Loss

### qalign

[Spherical Graph Embedding for Item Retrieval in Recommendation System](https://dl.acm.org/doi/abs/10.1145/3511808.3557704)

[自己下载了](../assets/Q-align.pdf)

代码：[https://github.com/WNQzhu/Q-align](https://github.com/WNQzhu/Q-align)

自己的注释：[https://github.com/daiwk/llms_new/blob/main/demos/qalign.py](https://github.com/daiwk/llms_new/blob/main/demos/qalign.py)


假设$$N_K(u)$$是节点$$u$$的$$K$$跳邻居，那么目标函数是最大化这些邻居的概率，即

XXX
\max _f \sum_{u \in \mathcal{V}} \log \operatorname{Pr}\left(N_K(u) \mid f(u)\right)
XXX

### BYOL

[Bootstrap your own latent: A new approach to self-supervised learning](https://arxiv.org/pdf/2006.07733)

![byol](../assets/byol.png)

loss是最小化两者的距离：

XXX
\mathcal{L}_{\theta, \xi} \triangleq\left\|\overline{q_\theta}\left(z_\theta\right)-\bar{z}_{\xi}^{\prime}\right\|_2^2=2-2 \cdot \frac{\left\langle q_\theta\left(z_\theta\right), z_{\xi}^{\prime}\right\rangle}{\left\|q_\theta\left(z_\theta\right)\right\|_2 \cdot\left\|z_{\xi}^{\prime}\right\|_2}
XXX

其中，$$\theta$$正常通过梯度下降更新，而$$\xi$$是stop-gradient的，通过对$$\theta$$进行moving average得到，在线只使用$$\theta$$对应的网络：

XXX
\begin{aligned}
& \theta \leftarrow \operatorname{optimizer}\left(\theta, \nabla_\theta \mathcal{L}_{\theta, \xi}^{\text {BYL }}, \eta\right), \\
& \xi \leftarrow \tau \xi+(1-\tau) \theta,
\end{aligned}
XXX

### label smoothing

[https://spaces.ac.cn/archives/7359](https://spaces.ac.cn/archives/7359)

Label smooth通过soft one-hot来加入噪声,减少了真实样本标签的类别在计算损失函数时的权重,而把剩余的权重均匀分配到其他类别上,使得模型不会盲目自信,最终在fine-grained任务上能有效抑制过拟合。


## 突破双塔

### TDM->JTM

[下一代深度召回与索引联合优化算法JTM](https://mp.weixin.qq.com/s/heiy74_QriwxpZRyTUEgPg)

### 二向箔

xx

### DR

[字节最新复杂召回模型，提出深度检索DR框架解决超大规模推荐系统中的匹配问题](https://cloud.tencent.com/developer/article/1698045)

[Deep Retrieval: An End-to-End Learnable Structure Model for Large-Scale Recommendations](https://arxiv.org/abs/2007.07203)

## 多兴趣召回

[推荐系统 多兴趣召回论文解读](https://zhuanlan.zhihu.com/p/404281900)

![](../assets/mind-comirec.png)

sdim：[https://zhuanlan.zhihu.com/p/560657191](https://zhuanlan.zhihu.com/p/560657191)

## 多场景

[多模态多兴趣多场景的召回算法](https://mp.weixin.qq.com/s/nBBPuwPBVC0JEB3trEk12g)

[M5: Multi-Modal Multi-Interest Multi-Scenario Matching for Over-the-Top Recommendation](https://dl.acm.org/doi/pdf/10.1145/3580305.3599863)

## transformer+召回

ICLR2020 cmu+google：

[Pre-training Tasks for Embedding-based Large-scale Retrieval](https://arxiv.org/abs/2002.03932)

## C-Star

[Shopping Trajectory Representation Learning with Pre-training for E-commerce Customer Understanding and Recommendation](https://assets.amazon.science/c3/ee/721654a94b0a800cb7c534ba5bd8/shopping-trajectory-representation-learning-with-pre-training-for-e-commerce-customer-understanding-and-recommendation.pdf)

Customer Shopping TrAjectory Representation Learning framework (C-STAR) 
PR-Graph（product relational graph）：$$\mathcal{G}=(\mathcal{T}, \mathcal{E}, \mathcal{V})$$

+ $$\mathcal{T}$$：所有节点，15k，可能是类目之类的，应该不是商品id
+ $$\mathcal{E}$$：所有边，417k，强关联的product才有边，例如共同购买
+ $$\mathcal{V}$$ ：每个节点对应的d维向量，$$\mathcal{V} \in \mathbb{R}^{|\mathcal{T}| \times d}$$。

用户的长度为$$N_i$$的历史序列就可以看成 $$\mathcal{T}_i \subseteq \mathcal{T} \text {, i.e., } \mathcal{T}_i=\left[t_n^i\right]_{n=1}^{N_i}$$，并构成了子图$$\mathcal{G}_i \subseteq \mathcal{G}$$

基于最优运输理论（Optimal Transport theory）：将一个分布的质量（mass）搬到另一个分布的最小成本

对于$$\boldsymbol{X} \sim P, \boldsymbol{X} \in \mathbb{R}^d$$，假设有一个函数$$f: \mathbb{R}^d \rightarrow \mathbb{R}$$，即$$f$$能把$$x$$从$$P$$分布变成另一个分布，称$$f_{\#} P$$是$$P$$的一个推前（push forward）。两个分布P和Q间的Wasserstein Distance定义为：

XXX
W_p(P, Q)=\left(\inf _{f \in T P(P, Q)} \int\|x-f(x)\|^p d P(x)\right)^{\frac{1}{p}}, p \geq 1
XXX

1维分布能直接算出最优距离，但对于高维分布来讲，没法直接算出来最优距离，SW距离(sliced-WD)通过将高维分布投影到一维，计算一维上的Wasserstein距离，然后对多个投影方向的距离取平均，从而降低计算复杂度。具体公式如下，其中$$g_{\boldsymbol{\theta}}(\boldsymbol{x})=\boldsymbol{\theta}^{\top} \boldsymbol{x}$$，而$$\boldsymbol{\theta} \in \mathbb{S}^{d-1}$$是一个d维的单位向量（unit vector，模长为1），$$\mathbb{S}^{d-1}$$是d维向量的超球面，$$g_{\theta_{\#}} P$$是$$P$$用$$g_{\boldsymbol{\theta}}$$的推前。这个距离同时满足正定、对称、三角不等式。

XXX
S W_p(P, Q)=\left(\int_{\mathbb{S}^{d-1}}\left(W_p\left(g_{\theta \#} P, g_{\theta \#} Q\right)\right)^p d \theta\right)^{\frac{1}{p}}
XXX

为了建模如下两种相似度：

+ inter-trajectory distribution similarity: 不同用户的行为序列间的分布相似度
+ intra-trajectory semantic correlation: 一个序列内部的语义相关性 


小结：参考最优传输理论（Optimal Transport），即把每个购物路径视为一个概率分布，然后通过计算这些分布之间的距离来衡量路径之间的相似性。Wasserstein距离可以视为将一个分布“移动”到另一个分布所需的“工作量”，其中“工作量”由移动每个元素所需的“成本”（通常是欧几里得距离）决定。
高维空间中直接计算Wasserstein距离很难，采用了Sliced-Wasserstein距离，将高维分布投影到多个一维分布上，然后将这些一维分布之间的Wasserstein距离进行pooling，来近似原始高维Wasserstein距离。

Inter-SE和Intra-CE简单总结如下：

+ Inter-trajectory similarity encoding(inter-SE)：把原分布的n维特征向量映射成1维，参考分布（可以是原来特征的向量的avg之类的）也映射成1维，计算映射后的向量与参考向量的距离（可以证明这个距离就约等于sliced-WD），作为inter-SE
+ Intra-trajectory correlation encoder(intra-CE)：取每个item在graph里的邻居，用GCN得到其表示，然后和inter-SE一样也映射成1维，算映射后的向量与inter-SE里的参考向量的距离，作为intra-SE

### 序列间

&nbsp;

对于$$M$$个序列，定义probability measures $$\left[P_i\right]_{i=1}^M$$，每个序列相对应的特征序列是$$\mathcal{V}_i=\left[v_{t_n^i} \in \mathbb{R}^d\right]_{n=1}^{N_i}$$，假设这些特征的底层分布是$$P_i$$，而对应的经验（离散）分布$$\widehat{P}_i$$对应的经验CDF是

XXX
F_{\widehat{P}_i}(x)=\frac{1}{N_i} \sum_{n=1}^{N_i} \delta\left(x \geq v_{t_n^i}\right)
XXX

其中$$\delta(\cdot)$$如果输入是0就返回1，否则返回0。认为$$\widehat{P}_i \approx P_i$$，所以后面直接用$$\widehat{P}_i$$来表示$$P_i$$。

为了衡量两个序列分布的相似性，希望比较输入的序列分布和一个可训练的参考分布（当成序列特征空间的『原点』）。引入参考分布$$P_0$$，对应的特征list $$\mathcal{V}_0=\left[v_{t_n^0} \in \mathbb{R}^d\right]_{n=1}^N$$，每个元素是可训练的emb

目标就是找到$$\left(P_0, P_i\right)$$的距离，然后指导对应的序列表示$$\left(E_0, E_i\right)$$的学习

先进行一维WD的分布slice的计算，假设$$g_\theta(\boldsymbol{x})$$是一个线性映射，定义$$P_i^{\boldsymbol{\theta}}:=g_{\boldsymbol{\theta} \#} P_i$$为$$P_i$$关于$$g_\theta$$的一个slice


#### Proposition 1

&nbsp;

从reference slice $$P_0^{\boldsymbol{\theta}}$$到输入分布slice $$P_i^{\boldsymbol{\theta}}$$的$$f^*$$可以表示为：

XXX
f^*\left(x^{\boldsymbol{\theta}} \mid \mathcal{V}_i^{\boldsymbol{\theta}}\right):=F_{P_i^{\boldsymbol{\theta}}}^{-1}\left(F_{P_0^{\boldsymbol{\theta}}}\left(x^{\boldsymbol{\theta}}\right)\right), \quad x^{\boldsymbol{\theta}} \in \mathcal{V}_0^{\boldsymbol{\theta}}
XXX

对应的CDF是$$F_{P_0^{\boldsymbol{\theta}}}\left(x^{\boldsymbol{\theta}}\right)=\frac{1}{N} \sum_{n=1}^N \delta\left(x^{\boldsymbol{\theta}}-\boldsymbol{\theta}^{\top} .\right.v_{t_n^0})$$是单调递增的。

#### Proposition 2

&nbsp;

如果我们知道按升序排序的$$\mathcal{V}_0^\theta$$(因为这原始embedding的slice，是一维的，所以可以排序)对应的每个输入$$x^\theta$$的排名$$\tau\left(x^{\boldsymbol{\theta}} \mid \mathcal{V}_0^{\boldsymbol{\theta}}\right)$$，而且$$N=N_i$$，那么最优的transport plan $$f^*$$可以表示为：

XXX
f^*\left(x^{\boldsymbol{\theta}} \mid \mathcal{V}_i^{\boldsymbol{\theta}}\right)=\operatorname{argmin}_{x^{\prime} \in \mathcal{V}_i^\theta}\left(\tau\left(x^{\prime} \mid \mathcal{V}_i^\theta\right)=\tau\left(x^{\boldsymbol{\theta}} \mid \mathcal{V}_0^{\boldsymbol{\theta}}\right)\right)
XXX


#### inter-trajectory similarity encoding

&nbsp;

对于每个分布slice的pair对$$\left(P_0^{\boldsymbol{\theta}}, P_i^{\boldsymbol{\theta}}\right)$$，最优的transport plan产生了最短的一组距离$$W_p\left(P_0^{\boldsymbol{\theta}}, P_i^{\boldsymbol{\theta}}\right)$$。$$\boldsymbol{\theta}_s$$表示从$$\mathbb{S}^{d-1}$$中采样的第$$s$$个映射的参数，那么对原始序列分布的累积SW距离如下：

XXX
S W_p\left(P_0, P_i\right) \approx\left(\frac{1}{S} \sum_{s=1}^S W_p\left(P_0^{\theta_s}, P_i^{\theta_s}\right)^p\right)^{\frac{1}{p}}
XXX

用$$\Theta=\left\{\boldsymbol{\theta}_s\right\}_{s=1}^S$$表示采样的映射参数集合，首先将$$P_0$$的embedding参考$$\mathcal{V}_0=\left[\boldsymbol{v}_{t_n^0}\right]_{n=1}^N$$里的向量$$O \in \mathbb{R}^{N \cdot S}$$进行如下编码，其中$$\text { || }$$表示innermost维度的concat操作：

XXX
\boldsymbol{O}:=\frac{1}{S N}\left\|_{s=1}^S\right\|_{n=1}^N \boldsymbol{\theta}_s^{\mathrm{T}} \boldsymbol{v}_{t_n^0}
XXX

给定输入特征list $$\mathcal{V}_i$$，定义inter-se（inter-trajectory similarity encoder）如下：

XXX
\operatorname{Inter}-\operatorname{SE}\left(\mathcal{V}_i \mid \Theta\right):=\frac{1}{S N}\left\|_{s=1}^S\right\|_{n=1}^N f^*\left(\boldsymbol{\theta}_s^{\top} v_{t_n^0} \mid \mathcal{V}_i^{\boldsymbol{\theta}_s}\right)-\boldsymbol{O}
XXX

其中$$E_i \in \mathbb{R}^{N \cdot S}$$是编码后的表示

定理1：对于任意两个输入序列及其对应分布$$P_i$$和$$P_j$$，他们对应的编码后表示$$E_i$$和$$E_j$$，有：

+ $$\left\|E_i-E_j\right\|_p \approx S W_p\left(P_i, P_j\right)$$
+ $$\left\|E_i\right\|_p \approx S W_p\left(P_i, P_0\right)$$

### 序列内

&nbsp;

对于序列$$\mathcal{G}_i$$里的每个节点而言，它的邻居节点特征集合$$\mathcal{N}_i=\left[v_{t_\alpha^i}\right]_{t_\alpha^i \in N g h\left(\mathcal{T}_i\right)}$$，其中$$N g h\left(\mathcal{T}_i\right)$$是$$\mathcal{T}_{\boldsymbol{i}}$$的元素在PR-Graph里的所有邻居。对于$$\mathcal{T}_i=\left[t_n^i\right]_{n=1}^{N_i}$$里的每个节点$$t_n^i$$，先将它在第$$l$$次迭代的邻居特征向量summarize起来：

XXX
v_{N g h\left(t_n^i\right)}^{(l)}=\sum_{t \in N g h\left(t_n^i\right)} \frac{w_{t, t_n^i}^{(l-1)}}{\sqrt{|N g h(t)|+1} \sqrt{\left|N g h\left(t_n^i\right)\right|+1}} v_{t_n^i}^{(l-1)}
XXX

其中$$w_{t, t_n^i}^{(l-1)} \in \mathbb{R}$$，$$v_{t_n^i}^{(0)}$$通过$$\mathcal{V}_i$$中的$$v_{t_n}^i$$初始化，定义如下的layer-wise邻居特征list：

XXX
\mathcal{N}_i^{(l)}=\left[v_{N g h\left(t_n^i\right)}^{(l)}\right]_{t_n^i \in \mathcal{T}_i}
XXX

最终定义Intra-Trajectory Correlation Encoder（Intra-CE）如下：

XXX
\operatorname{Intra-CE}\left(\mathcal{V}_i \mid \Theta\right):=\sum_{l=1}^L \alpha_l\left(\frac{1}{S N}\left\|_{s=1}^S\right\|_{n=1}^N f^*\left(\boldsymbol{\theta}_s^{\top} \boldsymbol{v}_{t_n^0} \mid \mathcal{N}_i^{(l)}\right)-\boldsymbol{O}\right)
XXX

其中$$\alpha_l$$是第$$l$$个系数，简单地定义为$$\alpha_l=1/L$$。节点的emb一般通过邻居信息迭代更新，例如$$v_{t_n^i}^{(l)}=\operatorname{AGG}\left(v_{N g h\left(t_n^i\right)}^{(l)}, v_{t_n^i}^{(l-1)}\right)$$，AGG就是GNN的聚合函数。

Inter-SE的输出是$$\boldsymbol{E}_{\boldsymbol{i}}$$，Intra-CE的输出是$$E_i^{\prime}$$，最终整个序列的表示是二者的融合$$E_i^{\star}=\left[\boldsymbol{E}_i, \boldsymbol{E}_i^{\prime}\right] \in \mathbb{R}^{2 N S}$$

### C-Star预训练策略

&nbsp;

两个loss：

+ 序列间的element overlaps：两个序列的overlap越多，越相似。用$$\Omega_i$$表示与$$\mathcal{T}_i$$相关的ranking list，检索出一个序列pair $$\left(\mathcal{T}_j, \mathcal{T}_k\right) \in \Omega_i$$，使得$$\left|\mathcal{T}_i \cap \mathcal{T}_j\right|>\left|\mathcal{T}_i \cap \mathcal{T}_k\right|$$，即$$i$$与$$j$$的交集比$$i$$与$$k$$的大，loss如下：

XXX
\mathcal{L}_1=\sum_{i=1}^M \sum_{\left(\mathcal{G}_j, \mathcal{G}_k\right) \in \Omega_i}^H \max \left(0,\left\|\boldsymbol{E}_i^{\star}-\boldsymbol{E}_j^{\star}\right\|_2-\left\|\boldsymbol{E}_i^{\star}-\boldsymbol{E}_k^{\star}\right\|_2+\text { margin }\right)
XXX

+ 序列内的contextual relalations：同一个序列里的是正样本，不同序列的是负样本，loss如下：

XXX
\mathcal{L}_2=\sum_{i=1}^M \sum_{t^{+} \in \mathcal{T}_i, t^{-} \notin \mathcal{T}_i}^H \max \left(0, \boldsymbol{E}_i^{\star} \cdot \boldsymbol{v}_{t^{+}}-\boldsymbol{E}_i^{\star} \cdot \boldsymbol{v}_{t^{-}}+\text {margin }\right)
XXX

整体loss，其中$$\|\Delta\|_2^2$$是正常的L2正则：

XXX
\mathcal{L}=\mathcal{L}_1+\mu \mathcal{L}_2+\mu^{\prime}\|\Delta\|_2^2
XXX

![c-star-algo](../assets/c-star-algo.png)



# 粗排

## COLD

## CAN

## poly-encoder

[https://zhuanlan.zhihu.com/p/119444637](https://zhuanlan.zhihu.com/p/119444637)

## VIRT

虚拟交互：让双塔模型向单塔模型模仿如何分配注意力权重

[VIRT: Improving Representation-based Text Matching via Virtual Interaction](https://aclanthology.org/2022.emnlp-main.59.pdf)

## HCCP

[WWW'25「京东」粗排一致性建模｜A Hybrid Cross-Stage Coordination Pre-rank](https://mp.weixin.qq.com/s/RFlWwaR6luoWEjabpwQ8JQ)

[A Hybrid Cross-Stage Coordination Pre-ranking Model for Online Recommendation Systems](https://arxiv.org/pdf/2502.10284)

构造5类样本：

+ N1：曝光空间中的点击/未点击作为正负样本；
+ N2：未曝光空间中的排序列表，非均匀采样；
+ N3：后链路排序后的粗排序列，非均匀采样；
+ N4：batch内的负采样，均匀采样；
+ N5：整个候选池负采样，均匀采样。

除了N1，其他样本都是额外构造的。非均匀采样是针对排序列表的，排在前面的采样率高。列表经过后链路的排序，可以增加与后链路的一致性。减少长尾item的采样可以防止长尾偏差。

然后对采样率进行分桶，对桶内进行重新排序，目的是减少后链路排序的偏差。新排序公式的思想是：和原始排序正相关，加上一定程度的和曝光/点击负相关。

多目标训练主要包括下游一致性和长尾优化。



# 精排

## 传统ctr

[https://daiwk.github.io/posts/dl-traditional-ctr-models.html](https://daiwk.github.io/posts/dl-traditional-ctr-models.html)


### lr for ctr

[Simple and scalable response prediction for display advertising](https://people.csail.mit.edu/romer/papers/TISTRespPredAds.pdf)

[Online Models for Content Optimization](https://www.researchgate.net/publication/221618458_Online_Models_for_Content_Optimization)

### gbdt for ctr

gbdt基础知识：

[https://zhuanlan.zhihu.com/p/86263786](https://zhuanlan.zhihu.com/p/86263786)

bagging全称叫bootstrap aggregating，每个基学习器都会对训练集进行有放回抽样得到子训练集，比较著名的采样法为0.632自助法。每个基学习器基于不同子训练集进行训练，并综合所有基学习器的预测值得到最终的预测结果。bagging常用的综合方法是投票法，票数最多的类别为预测类别。

boosting训练过程为阶梯状，基模型的训练是有顺序的，每个基模型都会在前一个基模型学习的基础上进行学习，最终综合所有基模型的预测值产生最终的预测结果，用的比较多的综合方式为加权法。

stacking是先用全部数据训练好基模型，然后每个基模型都对每个训练样本进行的预测，其预测值将作为训练样本的特征值，最终会得到新的训练样本，然后基于新的训练样本进行训练得到模型，然后得到最终预测结果。

bagging和stacking中的基模型为强模型（偏差低，方差高），而boosting中的基模型为弱模型（偏差高，方差低）。

bagging的特点：

+ 整体模型的期望等于基模型的期望，这也就意味着整体模型的偏差和基模型的偏差近似。
+ 整体模型的方差小于等于基模型的方差，当且仅当相关性为1时取等号，随着基模型数量增多，整体模型的方差减少，从而防止过拟合的能力增强，模型的准确度得到提高。

所以，bagging中的基模型一定要为强模型，如果bagging使用弱模型则会导致整体模型的偏差提高，而准确度降低。

boosting的特点：

+ 整体模型的方差等于基模型的方差，如果基模型不是弱模型，其方差相对较大，这将导致整体模型的方差很大，即无法达到防止过拟合的效果。因此，boosting框架中的基模型必须为弱模型。
+ boosting框架中采用基于贪心策略的前向加法，整体模型的期望由基模型的期望累加而成，所以随着基模型数的增多，整体模型的期望值增加，整体模型的准确度提高。


gbdt与Adaboost对比

相同：

+ 都是boosting，使用弱分类器；
+ 都使用前向分布算法；

不同：

+ 迭代思路不同：adaboost是通过提升错分数据点的权重来弥补模型的不足（利用错分样本），而GBDT是通过算梯度来弥补模型的不足（利用残差）；
+ 损失函数不同：adaBoost采用的是指数损失，GBDT使用的是绝对损失或者Huber损失函数；

[Learning the click-through rate for rare/new ads from similar ads](https://www.researchgate.net/publication/221299556_Learning_the_click-through_rate_for_rarenew_ads_from_similar_ads)

[Using boosted trees for click-through rate prediction for sponsored search](https://www.researchgate.net/publication/254463616_Using_boosted_trees_for_click-through_rate_prediction_for_sponsored_search)

[Improving Ad Relevance in Sponsored Search](https://www.researchgate.net/publication/221520094_Improving_Ad_Relevance_in_Sponsored_Search)

[Stochastic Gradient Boosted Distributed Decision Trees](../assets/gbdt-Stochastic%20Gradient%20Boosted%20Distributed%20Decision%20Trees.pdf)

[https://zhuanlan.zhihu.com/p/148050748](https://zhuanlan.zhihu.com/p/148050748)

## 深度学习ctr

[https://daiwk.github.io/posts/dl-dl-ctr-models.html](https://daiwk.github.io/posts/dl-dl-ctr-models.html)



## 序列建模

[一文看懂序列推荐建模的最新进展与挑战](https://mp.weixin.qq.com/s/RQ1iBs8ftvNR0_xB7X8Erg)

[从MLP到Self-Attention，一文总览用户行为序列推荐模型](https://mp.weixin.qq.com/s/aMqh79_jjgSCn1StuCvyRw)

[Transformer在推荐模型中的应用总结](https://zhuanlan.zhihu.com/p/85825460)


[阿里妈妈点击率预估中的长期兴趣建模](https://mp.weixin.qq.com/s/RQ1iBs8ftvNR0_xB7X8Erg)

[DCN V2：Google提出改进版DCN，用于大规模排序系统中的特征交叉学习(附代码)](https://zhuanlan.zhihu.com/p/353223660)

[抖音/阿里/美团/微信/快手长序列兴趣建模经典方案探索](https://mp.weixin.qq.com/s/xKsT8b9cwrD1i8l-oSQ25g)

## 保序回归

参考[https://zhuanlan.zhihu.com/p/88623159](https://zhuanlan.zhihu.com/p/88623159)的代码，能画出下面的图

![](../assets/baoxuhuigui.png)

对于二分类问题，参考[https://zhuanlan.zhihu.com/p/101766505](https://zhuanlan.zhihu.com/p/101766505)

对lr+gbdt的负采样校准的方法

[Practical Lessons from Predicting Clicks on Ads at Facebook](https://scontent-itm1-1.xx.fbcdn.net/v/t39.8562-6/240842589_204052295113548_74168590424110542_n.pdf?_nc_cat=109&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=GSRnP2abLiwAX8Hp1xi&_nc_ht=scontent-itm1-1.xx&oh=00_AfCVWcm3VWKykwQMPU9lJxZk4WP9rJP1PJE_aIeLILLIHA&oe=641F3A4A)


## cvr预估

ecpc：用户给定一个粗粒度出价，模型可以在一定的范围内调价
ocpc：完全以模型出价为准

delay feedback
[https://zhuanlan.zhihu.com/p/555950153](https://zhuanlan.zhihu.com/p/555950153)


## 时长预估

快手kdd 2022

[Deconfounding Duration Bias in Watch-time Prediction for Video Recommendation](https://arxiv.org/pdf/2206.06003.pdf)

[短视频推荐视频时长bias问题](https://cloud.tencent.com/developer/article/2141921)

拿物理时长（duration）分桶

D2Q 算法的具体做法如下：

+ 统计训练样本的 duration 分布，得到等频分桶分位点；
+ 将样本按照等频分桶分位点分成 k 个相互独立的分桶 $$D_k$$；
+ 对不同 duration 分桶的样本，在组内统计时长分位数作为 label，得到 Duration-Aware Watchtime-Distribution label；
+ 分别在上述的分桶上训练时长预估模型 $$f_k$$；

![](../assets/wtd.png)

+ 图a：M个网络完全独立，分别学习各自的label，不共享特征 embedding，特征 embedding 空间随着分桶维度扩大线性增加，存储、训练的资源开销随之增加，实现成本较高，不符合工业界场景的要求；
+ 图b：M个网络共享底层特征，如果采用多输出的训练方式，则 batch 内样本分布不均的问题会导致子塔训练不稳定，收敛到局部最优。**单塔单输出**的训练方式在实际训练时效果稳定，收敛速度较快，是 D2Q 实现的基线版本。
+ 图c：单塔单输出模型中引入 Duration bias 模块，用于建模不同分桶下的样本差异（Res-D2Q），离线训练指标得到进一步的提升。


论文使用 XAUC、XGAUC 以及 MAE 等指标对时长回归效果进行评估。MAE 表示短视频预估时长与观看时长 label 的误差绝对值，表示模型回归精度，是回归任务的常用评估指标。

+ XAUC：将测试集中的样本两两组合，若组合的标签和预估值的序一致则为正序，否则为逆序，XAUC 是正序对数与总组合数的比值；
+ XGAUC：用户维度计算的 XAUC。

由于推荐系统主要优化候选集的排序，评估指标 XAUC 能够更加直观的反映预估时长序的好坏，与论文的优化目标更加适配。


## SUM

[2024 META新作：SUM技术进行大规模在线用户表示，提升广告个性化效果](https://mp.weixin.qq.com/s/aX4diMBe3mRgp0cSRUX3pA)

[Scaling User Modeling: Large-scale Online User Representations for Ads Personalization in Meta](https://arxiv.org/pdf/2311.09544)

![sum](../assets/sum.png)

## LTV——slateQ

[SlateQ: A Tractable Decomposition for Reinforcement Learning with Recommendation Set](https://storage.googleapis.com/gweb-research2023-media/pubtools/5096.pdf)

在ranking阶段，引入长期目标

## ranking loss引入

[KDD 2024 | 深入理解推荐模型中的辅助排序损失](https://mp.weixin.qq.com/s/Y4ErK09-_TSJ2m6lC6UGCA)


## Wukong

[Wukong: Towards a Scaling Law for Large-Scale Recommendation](https://arxiv.org/pdf/2403.02545.pdf)



# 多目标

## 多目标+推荐综述

[Multi-task多任务模型在推荐算法中应用总结1](https://zhuanlan.zhihu.com/p/78762586)

[Multi-task多任务学习在推荐算法中应用(2）](https://zhuanlan.zhihu.com/p/91285359)

[多任务学习在推荐算法中的应用](https://mp.weixin.qq.com/s/-SHLp26oGDDp9HG-23cetg)

## 阿里多目标

[阿里提出多目标优化全新算法框架，同时提升电商GMV和CTR](https://mp.weixin.qq.com/s/JXW--wzpaFwRHSSvZEA0mg)

## Youtube多目标——MMoE

[YouTube 多目标排序系统：如何推荐接下来收看的视频](https://mp.weixin.qq.com/s/0vZqCswErlggD6S52GnYVA)

[https://daiwk.github.io/posts/dl-youtube-multitask.html](https://daiwk.github.io/posts/dl-youtube-multitask.html)

## CGC

cgc参考paddle代码：[cgc_demo.py](../assets/cgc_dir/cgc_demo.py)

# 多场景

## APG

APG: 面向CTR预估的自适应参数生成网络

摘要：目前基于深度学习的CTR预估模型（即 Deep CTR Models）被广泛的应用于各个应用中。传统的 Deep CTR Models 的学习模式是相对静态的，即所有的样本共享相同的网络参数。然而，由于不同样本的特征分布不尽相同，这样一种静态方式很难刻画出不同样本的特性，从而限制了模型的表达能力，导致次优解。在本文中，我们提出了一个高效率、高效果的通用模块，称为自适应参数生成网络(APG)。其可以基于不同的样本，动态的为CTR模型生成不同的模型参数。大量的实验表明，APG 能够被应用于各种 CTR 模型，并且显著的提升模型效果，同时能节省38.7%的时间开销和96.6%的存储。APG 已在阿里巴巴搜索广告系统部署上线，并获得3%的点击率增长和1%的广告收入增长。

[APG: Adaptive Parameter Generation Network for Click-Through Rate Prediction](https://arxiv.org/abs/2203.16218)

# 重排

## LRF

[Learned Ranking Function: From Short-term Behavior Predictions to Long-term User Satisfaction](https://www.arxiv.org/pdf/2408.06512)，rank阶段得到多目标的输出，需要把它们融合成一个目标，拿这个去排序，例如加法融合，LRF就是对其中搜参方法的优化


## NAR4Rec

[KDD 2024 | 快手生成式推荐](https://mp.weixin.qq.com/s/2Clup2_JPELWBuHqMBc97w)

[Non-autoregressive Generative Models for Reranking Recommendation](https://arxiv.org/pdf/2402.06871)

# item冷启

poso 

[Personalized Cold Start Modules for Large-scale Recommender Systems](https://arxiv.org/abs/2108.04690)

[https://zhuanlan.zhihu.com/p/534056942](https://zhuanlan.zhihu.com/p/534056942)

# 用户冷启

## PeterRec

[仅需少量视频观看数据，即可精准推断用户习惯：腾讯、谷歌、中科大团队提出迁移学习架构PeterRec](https://mp.weixin.qq.com/s/PmVhAthYxiUspWic5Klpog)

[Parameter-Efficient Transfer from Sequential Behaviors for User Modeling and Recommendation](https://arxiv.org/pdf/2001.04253.pdf)

[https://github.com/fajieyuan/sigir2020_peterrec](https://github.com/fajieyuan/sigir2020_peterrec)

搞一个pretrain-finetune的架构，学好一套用户的表示，可以给各种下游任务用。

采用如下方式：

+ **无监督**地学习用户表示：使用**序列模型**，**预测**用户的**下一次点击**。为了能建模**超长**的u-i交互序列，使用类似NextItNet（[A Simple Convolutional Generative Network for Next Item Recommendation](https://arxiv.org/pdf/1808.05163.pdf)）的模型
+ 使用预训练好的模型去**有监督**地finetune下游任务
+ 在各个下游任务间，想要尽可能共享更多的网络参数：参考learning to learn，即一个网络的大部分参数可以其他参数来预测（一层里95%的参数可以通过剩下的5%的参数来预测）。文章提出了model patch(模型补丁)，每个模型补丁的参数量不到原始预训练模型里的卷积层参数的10%。通过加入模型补丁，不仅可以保留原来的预训练参数，还可以更好地适应下游任务。模型补丁有串行和并行两种加入方式。

序列推荐模型:

+ RNN：强序列依赖
+ CNN：可并行，能比RNN叠更多层，所以准确率更高。难以建模长序列是因为卷积核一般都比较小（如3x3），但可以通过空洞(dilated)卷积来解决，可以使用不变的卷积核，指数级地扩充表示域。
+ 纯attention：可并行，例如SASRec（[Self-attentive sequential recommendation](https://arxiv.org/abs/1808.09781)）。但因为时间和存储消耗是序列长度的平方的复杂度。

考虑到用户的点击序列往往成百上千，所以使用类似NextItNet的casual卷积，以及类似GRec（[Future Data Helps Training: Modeling Future Contexts for Session-based Recommendation](https://arxiv.org/abs/1906.04473)）的双向encoder的这种non-casual卷积。

与推荐系统现有的transfer learning对比：

+ DUPN：
  + 训练的时候就有多个loss。如果没有相应的loss和data，学好的用户表示效果就会很差。而本文只有一个loss，却能用在多个task上，所以算是一种multi-domain learning([Efficient parametrization of multi-domain deep neural networks](https://arxiv.org/abs/1803.10082))
  + DUPN在用户和item特征上需要很多特征工程，并没有显式地对用户的行为序列建模
  + DUPN要么finetune所有参数，要么只finetune最后一个分类层。PeterRec则是对网络的一小部分进行finetune，效果并不比全finetune差，比只finetune最后一个分类层要好很多

+ CoNet：杨强提出的[Conet: Collaborative cross networks for cross-domain recommendation](https://arxiv.org/abs/1804.06769)
  + cross-domain用于推荐的一个网络。同时训练2个目标函数，一个表示source网络，一个表示target网络。
  + pretrain+finetune效果不一定好，取决于预训练的方式、用户表示的表达能力、预训练的数据质量等

预训练时没有\[TCL\]，fintune时加上。

+ 原domain$$S$$：有大量用户交互行为的图文或视频推荐。一条样本包括$$\left(u, x^{u}\right) \in \mathcal{S}$$，其中，$$x^{u}=\left\{x_{1}^{u}, \ldots, x_{n}^{u}\right\}\left(x_{i}^{u} \in X\right)$$表示用户的点击历史
+ 目标domain$$T$$：可以是用户label很少的一些预测任务。例如用户可能喜欢的item、用户性别、用户年龄分桶等。一条样本包括$$(u, y) \in \mathcal{T}$$，其中$$y \in \mathcal{Y}$$是一个有监督的标签。

# GNN+推荐

[https://zhuanlan.zhihu.com/p/323302898](https://zhuanlan.zhihu.com/p/323302898)

[Graph Neural Networks in Recommender Systems: A Survey](https://arxiv.org/pdf/2011.02260.pdf)

[Graph Neural Networks for Recommender Systems: Challenges, Methods, and Directions](https://arxiv.org/pdf/2109.12843.pdf)

[https://daiwk.github.io/posts/dl-graph-representations.html](https://daiwk.github.io/posts/dl-graph-representations.html)


[SIGIR2022 \| SimGCL: 面向推荐系统的极简图对比学习方法](https://zhuanlan.zhihu.com/p/509511858)

[Are Graph Augmentations Necessary? Simple Graph Contrastive Learning for Recommendation](https://arxiv.org/abs/2112.08679)

[https://github.com/Coder-Yu/QRec](https://github.com/Coder-Yu/QRec)

## selfGNN

[图神经网络加持，突破传统推荐系统局限！北大港大联合提出SelfGNN：有效降低信息过载与数据噪声影响](https://mp.weixin.qq.com/s/j0ARLIk1lylp4UO_-6tKCw)

[SelfGNN: Self-Supervised Graph Neural Networks for Sequential Recommendation](https://arxiv.org/pdf/2405.20878)

[https://github.com/HKUDS/SelfGNN](https://github.com/HKUDS/SelfGNN)

# RL

[快手强化学习与多任务推荐](https://mp.weixin.qq.com/s/QWnpM_n0RcP8nXlwXkuTlg)

# bias v.s. debias

[推荐系统炼丹笔记：推荐系统Bias大全 \| Debias方法综述](https://blog.csdn.net/m0_52122378/article/details/110950122)

## position bias

[搜索、推荐业务中 - position bias的工业界、学术界 发展历程 - 系列1(共计2)](https://zhuanlan.zhihu.com/p/79904391)

[推荐系统遇上深度学习(七十一)-\[华为\]一种消除CTR预估中位置偏置的框架](https://www.jianshu.com/p/37768b399cd8)

### PAL

[PAL: A Position-bias Aware Learning Framework for CTR Prediction in Live Recommender Systems](https://dl.acm.org/citation.cfm?id=3347033)

参考2007年的[Predicting Clicks: Estimating the Click-Through Rate for New Ads](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/predictingclicks.pdf)一文中的推导，

给定位置$$pos$$和对应的item $$x$$，用户点击的概率可以分解为：

+ 给定$$pos$$和$$x$$，用户看到的概率$$P(seen|x,pos)$$
+ 给定$$pos$$和$$x$$，用户看到后，点击的概率$$P(clk|seen, pos, x)$$

所以

XXX
P(clk|x,pos) = P(seen|x,pos) * P(clk|seen, pos, x) 
XXX

假设：

+ 用户没看到item，那么点击概率为0
+ 用户是否点击item和位置无关，只取决于用户是否看到item，即$$P(clk|seen, pos, x)=P(clk|x,seen)$$
+ item被看到的概率只和位置有关，和item本身无关，即$$P(seen|x,pos) = P(seen|pos)$$

XXX
P(clk|x,pos)=P(seen|pos)P(clk|x, seen)
XXX

PAL就是搞两个塔：

+ **仅bias塔**：$$P(seen|pos)$$：输入pos等bias特征，预估用户会不会看到**仅训练时使用**
+ **无bias塔**：$$P(clk|x, seen)$$：输入item特征，预估**无bias的点击率**，**线上infer用**
+ **带bias预估值**：两个塔输出乘起来，预估**有bias的点击率**，**仅训练时使用**


[推荐系统之Position-Bias建模](https://mp.weixin.qq.com/s/as8MWJZ2SAVZedx2v02fmA)


# 数据集的一些处理

[KDD2024最佳学生论文解读，中科大、华为诺亚：序列推荐新范式DR4SR](https://mp.weixin.qq.com/s/kvSMzc_8NXGKvPN66rDhtg)

[Dataset Regeneration for Sequential Recommendation](https://arxiv.org/abs/2405.17795)

[https://github.com/USTC-StarTeam/DR4S](https://github.com/USTC-StarTeam/DR4S)

# 工业界的一些推荐应用

## dlrm

[Facebook深度个性化推荐系统经验总结(阿里内部分享PPT))](https://mp.weixin.qq.com/s/_LBSM_E0tNqVgLhLtULmUQ)


## instagram推荐系统

[Facebook首次揭秘：超过10亿用户使用的Instagram推荐算法是怎样炼成的？](https://mp.weixin.qq.com/s/LTFOw1jSgMogANT8gmCTpw)

[https://venturebeat.com/2019/11/25/facebook-details-the-ai-technology-behind-instagram-explore/](https://venturebeat.com/2019/11/25/facebook-details-the-ai-technology-behind-instagram-explore/)

[Instagram个性化推荐工程中三个关键技术是什么？](https://mp.weixin.qq.com/s/yBmISlPeRB9-mKv2-Dv6LQ)

## 微信读书推荐系统

[微信读书怎么给你做推荐的？](https://mp.weixin.qq.com/s/TcxI-XSjj7UtHvx3xC55jg)

## youtube推荐梳理

[一文总览近年来YouTube推荐系统算法梳理](https://mp.weixin.qq.com/s/hj2ecwfrwCfvrafnsNiP-g)

## 小红书

[小红书推荐系统全解析：去中心化内容分发](https://mp.weixin.qq.com/s/QAei__DLF-agcVHrWM5EaA)

中心化分发问题的本质在于**曝光越多、活跃度越高的内容**，往往能**获得更多的分发**，致使**普通创作者**的内容分发效果相对较差。此外，用户可能也会频繁看到热门兴趣，导致自身中长尾兴趣的内容所见相对较少。若要构建生态良好的社区，去中心化分发问题是需要解决的核心问题。

+ 对于内容侧而言，应设法通过多种方式识别和引入笔记本身的更多信号，而非仅依赖用户对笔记的行为进行分发。
+ 对于用户侧来说，应设法对用户的兴趣进行更优的挖掘，并在挖掘后予以一定的保护，鼓励用户中长尾和小众兴趣的内容分发，使用户的兴趣得到更全面的满足。

参考蚂蚁的[Bootstrap Latent Representations for Multi-Modal Recommendation](https://arxiv.org/pdf/2207.05969)的BM3：

![BM3](../assets/bm3.png)

+ $$L_{rec}$$：uid没mask和itemid mask的搞，uid mask的和itemid没mask的搞
+ $$L_{align}$$：itemid mask的和多模态没mask的搞
+ $$L_{mask}$$：多模态没mask的和多模态mask的搞

# 其他

## 混合推荐架构

[混合推荐系统就是多个推荐系统“大杂烩”吗?](https://mp.weixin.qq.com/s/-OwxXZmbjrcpDtH-hWN-oQ)

## 认知推荐

[NeurIPS 2019 \| 从感知跃升到认知，这是阿里在认知智能推荐领域的探索与应用](https://mp.weixin.qq.com/s/MzF-UT5Hm071bTUTZpKDGw)

[Learning Disentangled Representations for Recommendation](https://arxiv.org/pdf/1910.14238.pdf)

