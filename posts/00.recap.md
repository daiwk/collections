## 一些回顾性的经典总结

### 2019年盘点

[告别2019：属于深度学习的十年，那些我们必须知道的经典](https://mp.weixin.qq.com/s/GT-o7nA9Fc_-4xhtUoFgvQ)

[“深度学习”这十年：52篇大神级论文再现AI荣与光](https://mp.weixin.qq.com/s/RYU6SBlD6FFkCVJk0VvGuA)

[Jeff Dean谈2020ML：专用芯片、多模态多任务学习，社区不用痴迷SOTA](https://mp.weixin.qq.com/s/w8zGd9x7li-1UA0PNvM9_g)

[NLPer复工了！先看看这份2019机器学习与NLP年度盘点吧](https://mp.weixin.qq.com/s/-Uk74MjhZtVroasFUFdmvA)

[三巨头共聚AAAI：Capsule没有错，LeCun看好自监督，Bengio谈注意力](https://mp.weixin.qq.com/s/nDDAx6AB9SYgQ9cVevjZvA)

Geoffrey Hinton 介绍了[Stacked Capsule Autoencoders](https://arxiv.org/abs/1906.06818)，即一种无监督版本的 Capsule 网络，这种神经编码器能查看所有的组成部分，并用于推断跟细节的特征；
Yann LeCun 在《Self-Supervised Learning》中再次强调了自监督学习的重要性；(nlp那章里讲到了)
Yoshua Bengio 在[Deep Learning for System 2 Processing](http://www.iro.umontreal.ca/~bengioy/AAAI-9feb2020.pdf)中回顾了深度学习，并讨论了当前的局限性以及前瞻性研究方向。

### 2019nlp

[2019 NLP大全：论文、博客、教程、工程进展全梳理（长文预警）](https://mp.weixin.qq.com/s/5T3-SxBTVzndULwKiFp4Hw)

### 2021年盘点

google research总结

[https://ai.googleblog.com/2022/01/google-research-themes-from-2021-and.html](https://ai.googleblog.com/2022/01/google-research-themes-from-2021-and.html)

[谷歌大神Jeff Dean领衔，万字展望5大AI趋势播报文章](https://baijiahao.baidu.com/s?id=1721742678416388422&wfr=spider&for=pc)

