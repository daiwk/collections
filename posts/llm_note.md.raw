参考[https://github.com/changyeyu/LLM-RL-Visualized](https://github.com/changyeyu/LLM-RL-Visualized)，对应的书《大模型算法：强化学习、微调与对齐》）

# 概述

llm训练时的teacher forcing机制：生成第i个token的输入：
+ 推理时：是模型生成的第0到第i-1的序列
+ 训练时：训练数据中实际的token序列

例如输入的是12345，输入1的时候生成了8，那要预测3的时候，输入的就是18；而训练时输入的还是12

# SFT

## lora

+ lora的核心思想：微调前后模型的参数差异具有低秩性，所以可以用A和B两个矩阵来表示，这两个矩阵的秩是$$lora_{rank}$$
+ A一般是随机初始化，**B用0初始化**或者用很小的随机数初始化，为了保证在训练初期，lora不会对原始输出造成太大扰动
+ 参数$$lora_{alpha}$$用于缩放Lora输出，即$$W_{merge}=W+A*B*lora_{alpha}/lora_{rank}$$
+ 学习率一般开始的时候比较小，后面可以再调整，不过如果lora_alpha较大，可以适当减小学习率
+ 在推理的时候，可以先进行融合，其实就是算好$$W_{merge}$$，推理的时候直接用

## prefix-tuning

大概是在prompt的最前面加若干个虚拟token，然后这部分有自己的参数（最开始的emb，还有后面的k和v，这里的k和v都是2个mlp，先映射到小一点的d'，再映射到d），总的可训练参数量参考：

![](../assets/prefix-tuning-params.png)

## sft loss与logsoftmax

+ LM head：从hidden dim映射到vocab size
+ 正常是先过LM head，算出logit矩阵，然后每个位置对所有词表里的词算softmax得到p，再去算交叉熵（只有label那个字有log(p)），所以就是log(softmax(x))
+ prompt没有loss，只有response有loss，假设response长度为k，假设第i个位置对应的label是j，那交叉熵是$$-1/k\sum_{i=1}^{k} log(p_ij)$$

对于response里的第i个词来说，词表大小为$$n$$，$$x_{max}=max(x_0,x_1,...,x_n)$$，下式第三行就是第二行分子分母同时乘$$e^{-x_{max}}$$

XXX
\begin{aligned}
\operatorname{LogSoftmax}\left(x_i\right) & =\log \left(\operatorname{Softmax}\left(x_i\right)\right) \\
& =\log \left(\mathrm{e}^{x_i} / \sum_{j=0}^n \mathrm{e}^{x_j}\right) \\
& =\log \left(\mathrm{e}^{\left(x_i-x_{\text {max }}\right)} / \sum_{j=0}^n \mathrm{e}^{\left(x_j-x_{\text {max }}\right)}\right) \\
& =\left(x_i-x_{\text {max }}\right)-\log \left(\sum_{j=0}^n \mathrm{e}^{\left(x_j-x_{\text {max }}\right)}\right)
\end{aligned}
XXX

这个简化有2个好处：

+ 减少计算量：例如除法、少量对数
+ 数值稳定：上式是log-sum-exp技巧，减掉max可以避免溢出

另外还有一个常用名词logprobs（log probabilities），即logsoftmax的结果，因为softmax是0到1，所以logprobs取值范围是负无穷到0

# 一些常用的参数

+ temperature：**控制不同词的概率差距**。当调小时，x/T变大，然后经过exp会指数放大，这样高logit的会变得更巨大，词的差距会被拉大，所以模型的输出会更稳定，输出结果更确定；反之不同词的差距更小，输出更多样
+ top-p：**控制长尾词的概率阈值**。top cummulative probability，是一个门槛，即从第一名往下数，累加后的概率大于p时，把后面的词扔掉，剩下的词再softmax，并去采样。调低会去掉长尾，输出稳定；调高会放低门槛，输出多样

temperature和top-p虽然原理不同，但均是越大越多样，适用创作等场景；越小越稳定，适用于代码、数学