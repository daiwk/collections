# 前言

最近随着[onerec](https://arxiv.org/abs/2506.13695)的pr，生成式推荐一下子就火起来了。发现深度学习第一次用到推荐的[youtubednn](https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45530.pdf)是recsys16的，转眼快十年过去了，就来简单讨论下生成式推荐

[transformer](https://arxiv.org/abs/1706.03762)是2017年的文章，[din](https://arxiv.org/abs/1706.06978)是同年并且中了kdd18，在那段时间就出现了很多尝试把lstm/rnn/transformer用到推荐里的工作，例如至今还是很多论文baseline的2018年的[sasrec](https://arxiv.org/abs/1808.09781)。那么，生成式推荐和它有啥区别吗?

说实话单看模型结构和loss真没啥区别..

但我觉得以下几点还是有一些价值的：

+ 现在的gpu卡比以前强无数倍了，模型大小可以尽情scale up上去，毕竟llm这么成熟，对应的一堆优化都是现成的
+ [tiger](https://arxiv.org/abs/2305.05065)提出了可以用rqvae之类的方法产出语义id(sid)来代替itemid，这样解码就可以有新的可能。以前召回因为候选巨大，都是ann，而sid其实类似很2020年字节的[dr](https://arxiv.org/abs/2007.07203)，有某一种聚类的含义，就算极限情况做到了sid和itemid的一对一唯一映射，sid的解码还是会很有优势。当然这里还可以引出另一个话题那就是推荐和多模态的结合
+ rlhf造就了chatgpt，onerec里把rl思想引进来了。看似很创新，但rl+推荐早在2018年的[topkoff policy correction reinforce](https://arxiv.org/abs/1812.02353)那个工作就被熟知了。不过借助着现在因为llm reasoning而带来的各种rl变种，应该会有一些新的思路吧
+ 链路合并的可能性，例如[hstu](https://arxiv.org/abs/2402.17152)号称统一召回+精排，onerec号称xxx，而真正的最大入口的场景能做到吗?毕竟堆积了那么多年的逻辑，是说替换就能替换的吗?现在互联网已经这么难了，不会造成更多的失业吗?但毕竟故事好听
+ 其他一些未知的可能性，llm毕竟也在飞速迭代，模型结构的创新、后训练的一些trick、llm世界知识怎么引入，甚至一些不需要训练的例如agent相关的东西，都有可能给现有的推荐算法有启发


如何将大模型应用到搜广推里？

个人觉得其实搜索是最容易用上的场景，因为搜索里相关性很重要，而文本天然就是其必不可少的输入，因此把模型从bert升级成llm就是一个最直接的想法了。而如果再叠加其他模态如图片、视频也同理，把对比学习训出来的如clip等模型升级成vlm应该也是一个相对可行的解法。

但推荐和广告似乎不太一样，因为国内最早的深度学习广告模型可以追溯到2014年百度的mio-learner（当然雅虎的lr模型是更早期的机器学习工作），时至今日，id类特征在推荐和广告模型里扮演着非常重要的作用，而搜索里最常用的文本和图片在推荐与广告里并不是那么重要。

所以，如何有效地把大模型引入到推荐和广告里呢？看过了一些论文后，发现有的挺有道理，有的包装过度，有的根本无法落地，这里就结合现有的（截止2025年7月）一些业界工作，简单地做一些个人感觉相对靠谱的思路上的总结（当然后续如果还有新思路的话会再更新下）

1. 参考大模型的结构与训练范式
  1. 精排中序列建模模块的升级：保留精排整体结构，只是将序列建模部分transformer化。因为改造成了transformer，那么在LLM研究领域里累积了很多年且还相当活跃attention的变种、MoE的变种，都是可以尝试的点
  2. 不断强化序列建模重要性：比较激进的是HSTU，直接只保留历史序列这一特征，别的全干掉了（当然论文附录里也说了其实推全的并不是这个）；比较保守的是美团的MTGR，保留了交叉特征。个人感觉合理的设计是介于二者之间，例如把序列建模模块的复杂度搞得足够高，那一些特征的作用就自然相对地弱化了
  3. pretrain+sft/rl范式：例如阿里的GPSD、Pinterest的PinFM，就是拆成了pretrain和finetune两个步骤；快手的OneRec则是引入了RL
  4. 训练/推理加速算子复用：如果模型里用到了decoder only的结构，那llm里常见的一些例如kv cache、pd分离、MTP都是可以参考的
2. 直接引入大模型的现有能力
  1. 用大模型产出item向量：可以理解为传统内容理解模型的升级，将bert升级为llm，clip升级为vlm，引入TIGER里通过RQ-VAE等方式得到的semantic id等
  2. 用大模型产出user向量：例如快手的LEARN，字节的HLLM，可能还会有新的方法，例如引入CoT等
  3. 用大模型的自然语言推理能力：直接做到id粒度的预估不太现实，一般是作用到某种聚类粒度。主要有2种场景：
    1. 场景1：很难找到groundtruth的场景，例如app的新用户，此时可以直接拿大模型进行预估
    2. 场景2：针对已经有一些行为的用户，如何结合大模型的知识尝试缓解信息茧房，此时就可以基于现有用户行为定义一些label，拿用户行为对大模型进行sft，例如google的惊喜度推荐的系列文章


# 概述

可以参考gpt生成的一些报告，目录[>>>](https://github.com/daiwk/collections/tree/master/deep-research-assets)

大模型=大语言模型或者多模态大模型

+ 引入大模型的模型结构
    + transformer结构的变种：tokenizer/位置编码/attention/ffn/moe/激活函数/norm等
    + loss：召回+排序loss
    + 生成式推荐：item粒度或sid粒度
+ 引入大模型的世界知识
    + item侧：跨模态内容理解、sid生成/映射
    + user侧：行为摘要、意图推理、embedding生成
+ 训练范式的创新
    + 预训练+sft+rl的流程：ExFM的蒸馏思路/搜广推的reward定义
    + 高效训练：LoRA、model merge（solar/sphinx等）等
    + 联合训练：大模型+搜广推模型联合训练
+ 推理范式的创新
    + 缓存：kvcache/pd分离等
    + 解码加速：beamsearch/speculative decoding/multi-token prediction等
    + 线上链路覆盖：召/粗/精/混
+ 探索性方向与未来趋势
    + 多智能体协同推荐
    + reasoning与链式思维的能力引入
    + 工具调用与RAG能力
    + 全模态的生成与沉浸式推荐

# 引入大模型的模型结构

## transformer结构的变种

tokenizer/位置编码/attention/ffn/moe/激活函数/norm等

## loss

召回+排序loss

## 生成式推荐

item粒度或sid粒度

# 引入大模型的世界知识

## item侧

跨模态内容理解、sid生成/映射

## user侧

行为摘要、意图推理、embedding生成

# 训练范式的创新

## 预训练+sft+rl的流程

ExFM的蒸馏思路/搜广推的reward定义

## 高效训练

LoRA、model merge（solar/sphinx等）等

## 联合训练

大模型+搜广推模型联合训练

# 推理范式的创新

## 缓存

kvcache/pd分离等

## 解码加速

beamsearch/speculative decoding/multi-token prediction等

## 线上链路覆盖

召/粗/精/混

# 探索性方向与未来趋势

## 多智能体协同推荐

## reasoning与链式思维的能力引入

## 工具调用与RAG能力

## 全模态的生成与沉浸式推荐

