## 语音算法

### 语音数据集

#### 中文音乐数据集

[中文歌词生成，缺不缺语料？这里有一个开源项目值得推荐](https://mp.weixin.qq.com/s/QKC46npREiCgJr6HKKLqpw)

[https://github.com/yangjianxin1/QQMusicSpider](https://github.com/yangjianxin1/QQMusicSpider)

数据集链接: [https://pan.baidu.com/s/1WNYLcOrd3hOiATu44gotBg](https://pan.baidu.com/s/1WNYLcOrd3hOiATu44gotBg) 提取码: cy6f

### 时域音频分离模型

[时域音频分离模型登GitHub热榜，效果超传统频域方法，Facebook官方出品](https://mp.weixin.qq.com/s/5ZVl2fRZifIDiNI-fU9YWw)

### 中文语音识别

[实战：基于tensorflow 的中文语音识别模型 \| CSDN博文精选](https://mp.weixin.qq.com/s/rf6X5Iz4IOVtTdT8qVSi4Q)

### 顺滑度

[赛尔原创 \| AAAI20 基于多任务自监督学习的文本顺滑研究](https://mp.weixin.qq.com/s/1DK-6GDLajm3r7JhbKfSLQ)

[Multi-Task Self-Supervised Learning for Disfluency Detection](http://ir.hit.edu.cn/~slwang/AAAI-WangS.1634.pdf)

自动语音识别（ASR）得到的文本中，往往含有大量的不流畅现象。这些不流畅现象会对后面的自然语言理解系统（如句法分析，机器翻译等）造成严重的干扰，因为这些系统往往是在比较流畅的文本上训练的。不流畅现象主要分为两部分，一部分是ASR系统本身识别错误造成的，另一部分是speaker话中自带的。NLP领域主要关注的是speaker话中自带的不流畅现象，ASR识别错误则属于语音识别研究的范畴。顺滑 (Disfluency Detection)任务的目的就是要识别出speaker话中自带的不流畅现象。
  
### 语音识别加速

[GPU解码提升40倍，英伟达推进边缘设备部署语音识别，代码已开源](https://mp.weixin.qq.com/s/6b-cmb8iVhYk50BpMYsNyQ)

### 唇读

[Hearing Lips: Improving Lip Reading by Distilling Speech Recognizers](https://arxiv.org/pdf/1911.11502.pdf)

年来，得益于深度学习和大型数据集的可用性，唇读（lip reading）已经出现了前所未有的发展。尽管取得了鼓舞人心的结果，但唇读的性能表现依然弱于类似的语音识别，这是因为唇读刺激因素的不确定性导致很难从嘴唇运动视频中提取判别式特征（discriminant feature）。

在本文中，来自浙江大学、斯蒂文斯理工学院和阿里巴巴的研究者提出了一种名为 LIBS（Lip by Speech）的方法，其目的是通过学习语音识别器来增强唇读效果。方法背后的基本原理是：提取自语音识别器的特征可能提供辅助性和判别式线索，而这些线索从嘴唇的微妙运动中很难获得，并且这些线索会因此促进唇阅读器的训练。具体而言，这是通过将语音识别器中的多粒度知识蒸馏到唇阅读器实现的。为了进行这种跨模式的知识蒸馏，研究者不仅利用有效的对齐方案来处理音频和视频之间长度不一致的问题，而且采用一种创造性的过滤策略来重新定义语音识别器的预测结果。研究者提出的方法在 CMLR 和 LRS2 数据集上取得了新的 SOTA 结果，在字符误差率（Character Error Rate，CER）方面分别超出基准方法 7.66% 和 2.75%。

### Live caption

[借助 Live Caption 在设备上生成字幕](https://mp.weixin.qq.com/s/lsTxYF2RU6iIvAe-6iviWw)

### demucs

[Demucs: Deep Extractor for Music Sources with extra unlabeled data remixed](https://arxiv.org/pdf/1909.01174v1.pdf)

[https://github.com/facebookresearch/demucs](https://github.com/facebookresearch/demucs)

在录制某些歌曲时，每种乐器都分别录制到单独的音轨或stem中。之后在混音和母带阶段，这些词干被合并在一起，生成歌曲。本文的目的是找到这一过程的逆向过程的方法，也就是说要从完成的歌曲中提取每个单独的stem。这个问题的灵感源自所谓“鸡尾酒会效应”，是说人脑可以从一个嘈杂的聊天室的环境中将单独对话分离出来，并专注于这个特定的对话，自带降噪效果。

本文提出的体系架构是SING神经网络体系结构和Wave-U-Net的思想的结合。前者用于符号到乐器的音乐合成，而后者是从混音中提取stem的方法之一。本质上是LSTM、卷积层与U-Net架构的结合。其中卷积层负责体系结构的编码，LSTM层用于解码。为了提高模型性能，本文中的架构不使用批量归一化层。

### 语音版bert

[语音版BERT？滴滴提出无监督预训练模型，中文识别性能提升10%以上](https://mp.weixin.qq.com/s/4wLR_9RVxbTsHKXf-1MLIw)

[Improving transformer-based speech recognition using unsupervised pre-training](https://arxiv.org/pdf/1910.09932.pdf)

### 搜狗录音笔

[投喂4万种噪声，20种语言方言实时转录，搜狗「开挂」录音笔这样炼成](https://mp.weixin.qq.com/s/p4uckiXAkVQVaJhfpISjOQ)

[非常时期，搜狗新一代“AI笔皇”问世！支持同声传译，转写准确率98%](https://mp.weixin.qq.com/s/KWnu_aHwHlhwDxJ2Cj-cZg)
