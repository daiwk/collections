## 参考LLM建模方式
------
[TIGER](https://arxiv.org/pdf/2305.05065.pdf) 
[HSTU](https://arxiv.org/pdf/2402.17152.pdf) 
[COBRA](https://arxiv.org/abs/2503.02453) 
[HeteroRec](https://arxiv.org/pdf/2503.01469) 

## 基于开源LLM

落地
------
[KAR](https://arxiv.org/pdf/2306.10933) 
[BAHE](https://arxiv.org/pdf/2403.19347) 
[LEARN](https://arxiv.org/pdf/2405.03988) 
[BEQUE](https://arxiv.org/pdf/2311.03758)

没落地
------
[SLIM](https://arxiv.org/pdf/2403.04260) 
[DLLM2Rec](https://arxiv.org/pdf/2405.00338v1) 
[LLM-CF](https://arxiv.org/pdf/2403.17688) 
[ILM](https://arxiv.org/pdf/2406.02844)
[EmbSum](https://www.arxiv.org/pdf/2405.11441)
[Agent4Ranking](https://arxiv.org/pdf/2312.15450)

学术界
------
[CUP](https://arxiv.org/pdf/2311.01314)
[LLaMA-E](https://arxiv.org/pdf/2308.04913)
[EcomGPT](https://arxiv.org/pdf/2308.06966v1)
[Llama4rec](https://arxiv.org/pdf/2401.13870) 
[SAGCN](https://arxiv.org/pdf/2312.16275) 
[GReaT](https://arxiv.org/pdf/2210.06280) 
[ONCE](https://arxiv.org/pdf/2305.06566)
[Agent4Rec](https://arxiv.org/pdf/2310.10108.pdf)
[RecPrompt](https://arxiv.org/pdf/2312.10463)
[PO4ISR](https://arxiv.org/pdf/2312.07552)
[TransRec](https://arxiv.org/pdf/2310.06491) 
[E4SRec](https://arxiv.org/pdf/2312.02443)

## 其他套路

------
[ExFM](https://arxiv.org/abs/2502.17494) 

------
[SLMRec](https://openreview.net/pdf?id=G4wARwjF8M) 
